{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy Hearst Patterns\n",
    "---\n",
    "\n",
    "In this experiment we test the utility of Hearst Patterns for detecting the ingroup and outgroup of a text.\n",
    "\n",
    "For this experiment spaCy matcher is used with code adapted from: https://github.com/mmichelsonIF/hearst_patterns_python/blob/master/hearstPatterns/hearstPatterns.py\n",
    "\n",
    "Hypernym relations are semantic relationships between two concepts: C1 is a hypernym of C2 means that C1 categorizes C2 (e.g. “instrument” is a hypernym of “Piano”). For this research, the phrase, \"America has enemies, such as Al Qaeda and the Taliban\" would return the following '[('Al Qaeda', 'enemy'), ('the Taliban', 'enemy')]'. In this example, the categorising term 'enemy' is a hypernym of both 'Al Qaeda' and the 'Taliban'; conversely 'al Qaeda' and 'the Tabliban' are hyponyms of 'enemy'. Using this technique, hypernym terms could be classified as ingroup or outgroup and named entities identified as hyponym terms could be identified as either group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_web_md\n",
      "['tagger', 'parser', 'ner', 'Named Entity Matcher', 'merge_entities', 'Concept Matcher', 'merge_custom_chunks', 'hearst pattern matcher']\n",
      "Wall time: 9.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import importlib\n",
    "from cndlib import pipeline\n",
    "# importlib.reload(cndlib.pipeline)\n",
    "\n",
    "cnd = pipeline.CND(\"medium\")\n",
    "print(cnd.nlp.meta['name'])\n",
    "print([pipe for pipe in cnd.nlp.pipe_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing:  hitler (2020-06-30) Mein Kampf\n",
      "parsing:  bush (2001-09-11) 911 Address to the Nation\n",
      "parsing:  bush (2001-09-14) Remarks at the National Day of Prayer & Remembrance Service\n",
      "parsing:  bush (2001-09-15) First Radio Address following 911\n",
      "parsing:  bush (2001-09-17) Address at Islamic Center of Washington, D.C.\n",
      "parsing:  bush (2001-09-20) Address to Joint Session of Congress Following 911 Attacks\n",
      "parsing:  bush (2001-10-07) Operation Enduring Freedom in Afghanistan Address to the Nation\n",
      "parsing:  bush (2001-10-11) 911 Pentagon Remembrance Address\n",
      "parsing:  bush (2001-10-11) Prime Time News Conference on War on Terror\n",
      "parsing:  bush (2001-10-11) Prime Time News Conference Q&A\n",
      "parsing:  bush (2001-10-26) Address on Signing the USA Patriot Act of 2001\n",
      "parsing:  bush (2001-11-10) First Address to the United Nations General Assembly\n",
      "parsing:  bush (2001-12-11) Address to Citadel Cadets\n",
      "parsing:  bush (2001-12-11) The World Will Always Remember 911\n",
      "parsing:  bush (2002-01-29) First (Official) Presidential State of the Union Address\n",
      "parsing:  king (1963-04-03) Ive Been to the Mountaintop\n",
      "parsing:  king (1963-08-28) I Have a Dream\n",
      "parsing:  king (1965-03-25) Our God is Marching On\n",
      "parsing:  king (1967-04-04) Beyond Vietnam\n",
      "parsing:  king (1967-04-14) The Other America\n",
      "parsing:  laden (1996-08-23) Declaration of Jihad Against the Americans Occupying the Land of the Two Holiest Sites\n",
      "parsing:  laden (2001-01-07) Osama Bin Laden Letter Calling For Global Islamic State\n",
      "parsing:  laden (2001-10-07) Al-Jazirah Carries Bin Ladin's Address on US Strikes\n",
      "parsing:  laden (2001-11-09) Bin Laden's Statement The Sword Fell\n",
      "parsing:  laden (2002-11-24) OBL Letter to America\n",
      "parsing:  laden (2004-11-01) Al Jazeera Speech\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import importlib\n",
    "from cndlib import cndobjects\n",
    "# importlib.reload(cndobjects)\n",
    "\n",
    "dirpath = r'C:\\Users\\spa1e17\\OneDrive - University of Southampton\\hostile-narrative-analysis\\dataset'\n",
    "\n",
    "orators = cndobjects.Dataset(cnd, dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1 - Comparing regex with spaCy results\n",
    "\n",
    "Having developed the spaCy pipeline component, this first test assesses improvement compared to the regex method.\n",
    "\n",
    "For this test the hp_Analysis function has been developed which iterates over the dataset, performs each of the detection methods on the text for each orator and records the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bush: 100%|██████████| 14/14 [00:22<00:00,  1.61s/it]\n",
      "king: 100%|██████████| 5/5 [00:20<00:00,  4.09s/it]\n",
      "laden: 100%|██████████| 6/6 [00:17<00:00,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import importlib\n",
    "from cndlib import hpspacy, hpregex, hpanalysis\n",
    "# importlib.reload(hpspacy)\n",
    "# importlib.reload(hpregex)\n",
    "# importlib.reload(hpanalysis)\n",
    "                 \n",
    "methods = {\"regex\" : hpregex.HearstPatterns(cnd.nlp, extended=True, merge = False).find_hyponyms,\n",
    "           \"spaCy\" : lambda t: cnd.nlp(t)._.pairs}\n",
    "\n",
    "analysis = hpanalysis.hp_Analysis(methods=methods, iterable=orators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from this test we can see the level of improvement for the number of patterns detected over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adolf Hitler</th>\n",
       "      <th>George Bush</th>\n",
       "      <th>Martin Luther King</th>\n",
       "      <th>Osama Bin Laden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>detected regex patterns</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detected spaCy patterns</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>42</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed analysis (regex)</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failed analysis (spaCy)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>improvement</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Adolf Hitler  George Bush  Martin Luther King  \\\n",
       "detected regex patterns             0           40                  26   \n",
       "detected spaCy patterns             0           75                  42   \n",
       "failed analysis (regex)             0            3                   0   \n",
       "failed analysis (spaCy)             0            0                   0   \n",
       "improvement                         0            0                   0   \n",
       "\n",
       "                         Osama Bin Laden  \n",
       "detected regex patterns               46  \n",
       "detected spaCy patterns               65  \n",
       "failed analysis (regex)                1  \n",
       "failed analysis (spaCy)                0  \n",
       "improvement                            0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(analysis.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "Here are some examples from George Bush's declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tonight we are a country awakened to danger and called to defend freedom.\n",
      "('be_a', a country, we)\n",
      "-----\n",
      "Whether we bring our enemies to justice, or bring justice to our enemies, justice will be done.\n",
      "('whether', resolution, we)\n",
      "-----\n",
      "The evidence we have gathered all points to a collection of loosely affiliated terrorist organizations known as al Qaeda.\n",
      "('know_as', a collection of loosely affiliated terrorist organizations, al Qaeda)\n",
      "-----\n",
      "The terrorists' directive commands them to kill Christians and Jews, to kill all Americans, and make no distinctions among military and civilians, including women and children.\n",
      "('include', civilians, women)\n",
      "-----\n",
      "The terrorists' directive commands them to kill Christians and Jews, to kill all Americans, and make no distinctions among military and civilians, including women and children.\n",
      "('include', civilians, children)\n",
      "-----\n",
      "This group and its leader -- a person named Usama bin Laden -- are linked to many other organizations in different countries, including the Egyptian Islamic Jihad and the Islamic Movement of Uzbekistan.\n",
      "('include', different countries, the Egyptian Islamic Jihad)\n",
      "-----\n",
      "This group and its leader -- a person named Usama bin Laden -- are linked to many other organizations in different countries, including the Egyptian Islamic Jihad and the Islamic Movement of Uzbekistan.\n",
      "('include', different countries, the Islamic Movement of Uzbekistan)\n",
      "-----\n",
      "They are recruited from their own nations and neighborhoods and brought to camps in places like Afghanistan, where they are trained in the tactics of terror.\n",
      "('like', places, Afghanistan)\n",
      "-----\n",
      "Release all foreign nationals, including American citizens, you have unjustly imprisoned.\n",
      "('include', all foreign nationals, American citizens)\n",
      "-----\n",
      "Our enemy is a radical network of terrorists, and every government that supports them.\n",
      "('be_a', a radical network of terrorists, Our enemy)\n",
      "-----\n",
      "They want to overthrow existing governments in many Muslim countries, such as Egypt, Saudi Arabia, and Jordan.\n",
      "('such_as', many Muslim countries, Egypt)\n",
      "-----\n",
      "They want to overthrow existing governments in many Muslim countries, such as Egypt, Saudi Arabia, and Jordan.\n",
      "('such_as', many Muslim countries, Saudi Arabia)\n",
      "-----\n",
      "They want to overthrow existing governments in many Muslim countries, such as Egypt, Saudi Arabia, and Jordan.\n",
      "('such_as', many Muslim countries, Jordan)\n",
      "-----\n",
      "It may include dramatic strikes, visible on TV, and covert operations, secret even in success.\n",
      "('include', It, dramatic strikes)\n",
      "-----\n",
      "It may include dramatic strikes, visible on TV, and covert operations, secret even in success.\n",
      "('include', It, covert operations)\n",
      "-----\n",
      "It may include dramatic strikes, visible on TV, and covert operations, secret even in success.\n",
      "('include', It, secret)\n",
      "-----\n",
      "I've called the Armed Forces to alert, and there is a reason.\n",
      "('be_a', a reason, there)\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import hpspacy\n",
    "importlib.reload(hpspacy)\n",
    "\n",
    "hs = hpspacy.HearstPatterns(cnd.nlp, extended = True)\n",
    "for pair in orators[\"bush\"][4].doc._.pairs:\n",
    "    print(str(pair[-1].sent).strip())\n",
    "    print(pair)\n",
    "    print(\"-\"*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hearst Pattern Detection Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There</td>\n",
       "      <td>are</td>\n",
       "      <td>works</td>\n",
       "      <td>by</td>\n",
       "      <td>such</td>\n",
       "      <td>authors</td>\n",
       "      <td>as</td>\n",
       "      <td>Herrick</td>\n",
       "      <td>,</td>\n",
       "      <td>Goldsmith</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There</td>\n",
       "      <td>are</td>\n",
       "      <td>works by such authors</td>\n",
       "      <td>as</td>\n",
       "      <td>Herrick</td>\n",
       "      <td>,</td>\n",
       "      <td>Goldsmith</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>Shakespeare</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1                      2   3        4        5          6  \\\n",
       "0  There  are                  works  by     such  authors         as   \n",
       "1  There  are  works by such authors  as  Herrick        ,  Goldsmith   \n",
       "\n",
       "         7    8            9 10    11           12    13  \n",
       "0  Herrick    ,    Goldsmith  ,   and  Shakespeare     .  \n",
       "1        ,  and  Shakespeare  .  None         None  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in-built chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>such_NOUN_as</td>\n",
       "      <td>(such, authors)</td>\n",
       "      <td>(Herrick)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>such_NOUN_as</td>\n",
       "      <td>(such, authors)</td>\n",
       "      <td>(Goldsmith)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>such_NOUN_as</td>\n",
       "      <td>(such, authors)</td>\n",
       "      <td>(Shakespeare)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in-built chunk predicate         hypernym        hyponym\n",
       "0             such_NOUN_as  (such, authors)      (Herrick)\n",
       "1             such_NOUN_as  (such, authors)    (Goldsmith)\n",
       "2             such_NOUN_as  (such, authors)  (Shakespeare)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There</td>\n",
       "      <td>are</td>\n",
       "      <td>such</td>\n",
       "      <td>benefits</td>\n",
       "      <td>as</td>\n",
       "      <td>postharvest</td>\n",
       "      <td>losses</td>\n",
       "      <td>reduction</td>\n",
       "      <td>,</td>\n",
       "      <td>food</td>\n",
       "      <td>increase</td>\n",
       "      <td>and</td>\n",
       "      <td>soil</td>\n",
       "      <td>fertility</td>\n",
       "      <td>improvement</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There</td>\n",
       "      <td>are</td>\n",
       "      <td>such</td>\n",
       "      <td>benefits</td>\n",
       "      <td>as</td>\n",
       "      <td>postharvest losses reduction</td>\n",
       "      <td>,</td>\n",
       "      <td>food increase</td>\n",
       "      <td>and</td>\n",
       "      <td>soil fertility improvement</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1     2         3   4                             5       6  \\\n",
       "0  There  are  such  benefits  as                   postharvest  losses   \n",
       "1  There  are  such  benefits  as  postharvest losses reduction       ,   \n",
       "\n",
       "               7    8                           9        10    11    12  \\\n",
       "0      reduction    ,                        food  increase   and  soil   \n",
       "1  food increase  and  soil fertility improvement         .  None  None   \n",
       "\n",
       "          13           14    15  \n",
       "0  fertility  improvement     .  \n",
       "1       None         None  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('such_NOUN_as', such benefits, postharvest losses reduction), ('such_NOUN_as', such benefits, food increase), ('such_NOUN_as', such benefits, soil fertility improvement)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>such_NOUN_as</td>\n",
       "      <td>(such, benefits)</td>\n",
       "      <td>(postharvest losses reduction)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>such_NOUN_as</td>\n",
       "      <td>(such, benefits)</td>\n",
       "      <td>(food increase)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>such_NOUN_as</td>\n",
       "      <td>(such, benefits)</td>\n",
       "      <td>(soil fertility improvement)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  custom chunk predicate          hypernym                         hyponym\n",
       "0           such_NOUN_as  (such, benefits)  (postharvest losses reduction)\n",
       "1           such_NOUN_as  (such, benefits)                 (food increase)\n",
       "2           such_NOUN_as  (such, benefits)    (soil fertility improvement)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There</td>\n",
       "      <td>were</td>\n",
       "      <td>bruises</td>\n",
       "      <td>,</td>\n",
       "      <td>lacerations</td>\n",
       "      <td>,</td>\n",
       "      <td>or</td>\n",
       "      <td>other</td>\n",
       "      <td>injuries</td>\n",
       "      <td>were</td>\n",
       "      <td>not</td>\n",
       "      <td>prevalent</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There</td>\n",
       "      <td>were</td>\n",
       "      <td>bruises</td>\n",
       "      <td>,</td>\n",
       "      <td>lacerations</td>\n",
       "      <td>,</td>\n",
       "      <td>or</td>\n",
       "      <td>other</td>\n",
       "      <td>injuries</td>\n",
       "      <td>were</td>\n",
       "      <td>not</td>\n",
       "      <td>prevalent</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1        2  3            4  5   6      7         8     9   10  \\\n",
       "0  There  were  bruises  ,  lacerations  ,  or  other  injuries  were  not   \n",
       "1  There  were  bruises  ,  lacerations  ,  or  other  injuries  were  not   \n",
       "\n",
       "          11 12  \n",
       "0  prevalent  .  \n",
       "1  prevalent  .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('other', other injuries, lacerations), ('other', other injuries, bruises)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>(other, injuries)</td>\n",
       "      <td>(lacerations)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>(other, injuries)</td>\n",
       "      <td>(bruises)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  custom chunk predicate           hypernym        hyponym\n",
       "0                  other  (other, injuries)  (lacerations)\n",
       "1                  other  (other, injuries)      (bruises)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in-built chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>other</td>\n",
       "      <td>(other, injuries)</td>\n",
       "      <td>(lacerations)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>other</td>\n",
       "      <td>(other, injuries)</td>\n",
       "      <td>(bruises)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in-built chunk predicate           hypernym        hyponym\n",
       "0                    other  (other, injuries)  (lacerations)\n",
       "1                    other  (other, injuries)      (bruises)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>common</td>\n",
       "      <td>law</td>\n",
       "      <td>countries</td>\n",
       "      <td>,</td>\n",
       "      <td>including</td>\n",
       "      <td>Canada</td>\n",
       "      <td>,</td>\n",
       "      <td>Australia</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>England</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>toast</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>common law countries</td>\n",
       "      <td>,</td>\n",
       "      <td>including</td>\n",
       "      <td>Canada</td>\n",
       "      <td>,</td>\n",
       "      <td>Australia</td>\n",
       "      <td>,</td>\n",
       "      <td>and</td>\n",
       "      <td>England</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>toast</td>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0    1          2       3          4          5  6  \\\n",
       "0                common  law  countries       ,  including     Canada  ,   \n",
       "1  common law countries    ,  including  Canada          ,  Australia  ,   \n",
       "\n",
       "           7        8      9       10     11     12    13  \n",
       "0  Australia        ,    and  England  enjoy  toast     .  \n",
       "1        and  England  enjoy    toast      .   None  None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('include', common law countries, Canada), ('include', common law countries, Australia), ('include', common law countries, England)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include</td>\n",
       "      <td>(common law countries)</td>\n",
       "      <td>(Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>include</td>\n",
       "      <td>(common law countries)</td>\n",
       "      <td>(Australia)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>include</td>\n",
       "      <td>(common law countries)</td>\n",
       "      <td>(England)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  custom chunk predicate                hypernym      hyponym\n",
       "0                include  (common law countries)     (Canada)\n",
       "1                include  (common law countries)  (Australia)\n",
       "2                include  (common law countries)    (England)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in-built chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>include</td>\n",
       "      <td>(common, law, countries)</td>\n",
       "      <td>(Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>include</td>\n",
       "      <td>(common, law, countries)</td>\n",
       "      <td>(Australia)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>include</td>\n",
       "      <td>(common, law, countries)</td>\n",
       "      <td>(England)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in-built chunk predicate                  hypernym      hyponym\n",
       "0                  include  (common, law, countries)     (Canada)\n",
       "1                  include  (common, law, countries)  (Australia)\n",
       "2                  include  (common, law, countries)    (England)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Many</td>\n",
       "      <td>countries</td>\n",
       "      <td>,</td>\n",
       "      <td>especially</td>\n",
       "      <td>France</td>\n",
       "      <td>,</td>\n",
       "      <td>England</td>\n",
       "      <td>and</td>\n",
       "      <td>Spain</td>\n",
       "      <td>also</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>toast</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Many</td>\n",
       "      <td>countries</td>\n",
       "      <td>,</td>\n",
       "      <td>especially</td>\n",
       "      <td>France</td>\n",
       "      <td>,</td>\n",
       "      <td>England</td>\n",
       "      <td>and</td>\n",
       "      <td>Spain</td>\n",
       "      <td>also</td>\n",
       "      <td>enjoy</td>\n",
       "      <td>toast</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0          1  2           3       4  5        6    7      8     9  \\\n",
       "0  Many  countries  ,  especially  France  ,  England  and  Spain  also   \n",
       "1  Many  countries  ,  especially  France  ,  England  and  Spain  also   \n",
       "\n",
       "      10     11 12  \n",
       "0  enjoy  toast  .  \n",
       "1  enjoy  toast  .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('especially', Many countries, especially France), ('especially', Many countries, England), ('especially', Many countries, Spain)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custom chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>especially</td>\n",
       "      <td>(Many, countries)</td>\n",
       "      <td>(especially, France)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>especially</td>\n",
       "      <td>(Many, countries)</td>\n",
       "      <td>(England)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>especially</td>\n",
       "      <td>(Many, countries)</td>\n",
       "      <td>(Spain)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  custom chunk predicate           hypernym               hyponym\n",
       "0             especially  (Many, countries)  (especially, France)\n",
       "1             especially  (Many, countries)             (England)\n",
       "2             especially  (Many, countries)               (Spain)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in-built chunk predicate</th>\n",
       "      <th>hypernym</th>\n",
       "      <th>hyponym</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>especially</td>\n",
       "      <td>(Many, countries)</td>\n",
       "      <td>(especially, France)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>especially</td>\n",
       "      <td>(Many, countries)</td>\n",
       "      <td>(England)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>especially</td>\n",
       "      <td>(Many, countries)</td>\n",
       "      <td>(Spain)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  in-built chunk predicate           hypernym               hyponym\n",
       "0               especially  (Many, countries)  (especially, France)\n",
       "1               especially  (Many, countries)             (England)\n",
       "2               especially  (Many, countries)               (Spain)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import importlib\n",
    "import hpspacy\n",
    "importlib.reload(hpspacy)\n",
    "\n",
    "\n",
    "texts = [\"There are works by such authors as Herrick, Goldsmith, and Shakespeare.\", # such_NOUN_as\n",
    "        \"There are such benefits as postharvest losses reduction, food increase and soil fertility improvement.\", # such_NOUN_as\n",
    "        \"There were bruises, lacerations, or other injuries were not prevalent.\",\n",
    "        \"common law countries, including Canada, Australia, and England enjoy toast.\", #noun, including noun\n",
    "        \"Many countries, especially France, England and Spain also enjoy toast.\", #noun, especially noun\n",
    "       ]\n",
    "\n",
    "hs = hpspacy.HearstPatterns(cnd.nlp, extended = True)\n",
    "for text in texts:\n",
    "    chunks = [[token for token in nlp(text)], [token for token in cnd(text)]]\n",
    "    \n",
    "    display(pd.DataFrame(_ for _ in itertools.zip_longest(*chunks)).T)\n",
    "    \n",
    "    custom_pairs = cnd(text)._.pairs\n",
    "    print(custom_pairs)\n",
    "    inbuilt_pairs = hs(nlp(text))._.pairs\n",
    "    \n",
    "    if custom_pairs: display(pd.DataFrame(custom_pairs, columns = [\"custom chunk predicate\", \"hypernym\", \"hyponym\"]))\n",
    "    \n",
    "    if inbuilt_pairs: display(pd.DataFrame(inbuilt_pairs, columns = [\"in-built chunk predicate\", \"hypernym\", \"hyponym\"]))\n",
    "    print('----------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Test of Hearst Pattern Detection Object\n",
    "\n",
    "First sentence contains a 'first' relationship' where hypernym preceeds hyponym.\n",
    "\n",
    "Second sentence contains both a 'first' and 'last' relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 #####\n",
      "custom chunks => [We, are, hunting, for, terrorist groups, ,, particularly, the, Taliban, and, al Qaeda]\n",
      "[]\n",
      "-----\n",
      "1 #####\n",
      "custom chunks => [We, are, hunting, for, the, IRA, ,, ISIS, ,, al Qaeda, and, some, other, terrorist groups, ,, especially, the, Taliban, ,, Web Scientists, and, particularly, Southampton University]\n",
      "[('some_other', some other terrorist groups, al Qaeda), ('some_other', some other terrorist groups, the IRA), ('some_other', some other terrorist groups, ISIS), ('some_other', some other terrorist groups, especially the Taliban), ('some_other', some other terrorist groups, Web Scientists), ('some_other', some other terrorist groups, particularly Southampton University)]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import hpspacy\n",
    "importlib.reload(hpspacy)\n",
    "\n",
    "texts = [\n",
    "    \"We are hunting for terrorist groups, particularly the Taliban and al Qaeda\",\n",
    "    \"We are hunting for the IRA, ISIS, al Qaeda and some other terrorist groups, especially the Taliban, Web Scientists and particularly Southampton University\"\n",
    "]\n",
    "\n",
    "hs = hpspacy.HearstPatterns(cnd.nlp, extended = True)\n",
    "def show_hyps(texts):\n",
    "    \n",
    "   \n",
    "    for i, text in enumerate(texts):\n",
    "        print(i, \"#####\")\n",
    "        print(\"custom chunks =>\", [token for token in cnd(text)])\n",
    "        print(cnd(text)._.pairs)\n",
    "        print('-----')\n",
    "\n",
    "show_hyps(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test With a Larger Number of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 #####\n",
      "custom chunks => [Forty-four percent, of, patients with uveitis, had, one, or, more, identifiable signs, or, symptoms, ,, such, as, red eye, ,, ocular pain, ,, visual acuity, ,, or, photophobia, ,, in, order of decreasing frequency, .]\n",
      "[('such_as', symptoms, red eye), ('such_as', symptoms, ocular pain), ('such_as', symptoms, visual acuity), ('such_as', symptoms, photophobia)]\n",
      "-----\n",
      "1 #####\n",
      "custom chunks => [Other, close friends, ,, including, Canada, ,, Australia, ,, Germany, and, France, ,, have, pledged, forces, as, the, operation, unfolds, .]\n",
      "[('include', Other close friends, Canada), ('include', Other close friends, Australia), ('include', Other close friends, Germany), ('include', Other close friends, France)]\n",
      "-----\n",
      "2 #####\n",
      "custom chunks => [The, evidence, we, have, gathered, all, points, to, a, collection of loosely affiliated terrorist organizations, known, as, al Qaeda, .]\n",
      "[('know_as', a collection of loosely affiliated terrorist organizations, al Qaeda)]\n",
      "-----\n",
      "3 #####\n",
      "custom chunks => [Terrorist groups, like, al Qaeda, depend, upon, the, aid, or, indifference, of, governments, .]\n",
      "[('like', Terrorist groups, al Qaeda)]\n",
      "-----\n",
      "4 #####\n",
      "custom chunks => [This, new, law, that, I, sign, today, will, allow, surveillance of all communications, used, by, terrorists, ,, including, e-mails, ,, the, Internet, ,, and, cell phones, .]\n",
      "[('include', terrorists, e-mails), ('include', terrorists, the Internet), ('include', terrorists, cell phones)]\n",
      "-----\n",
      "5 #####\n",
      "custom chunks => [From, this day, forward, ,, any, nation, that, continues, to, harbor, or, support, terrorism, will, be, regarded, by, the United States, as, a, hostile regime, .]\n",
      "[]\n",
      "-----\n",
      "6 #####\n",
      "custom chunks => [We, are, looking, out, for, the, Taliban, ,, al Qaeda, and, other, terrorist groups]\n",
      "[('other', other terrorist groups, al Qaeda)]\n",
      "-----\n",
      "7 #####\n",
      "custom chunks => [We, are, looking, out, for, al Qaeda, and, other, terrorist groups, ,, especially, the, Taliban, and, the, muppets]\n",
      "[('other', other terrorist groups, al Qaeda), ('other', other terrorist groups, especially the Taliban), ('other', other terrorist groups, the muppets)]\n",
      "-----\n",
      "Wall time: 494 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import importlib\n",
    "import hpspacy\n",
    "importlib.reload(hpspacy)\n",
    "\n",
    "# create a list of docs\n",
    "texts = [\n",
    "    \"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\",\n",
    "    \"Other close friends, including Canada, Australia, Germany and France, have pledged forces as the operation unfolds.\",\n",
    "    \"The evidence we have gathered all points to a collection of loosely affiliated terrorist organizations known as al Qaeda.\",\n",
    "    \"Terrorist groups like al Qaeda depend upon the aid or indifference of governments.\",\n",
    "    \"This new law that I sign today will allow surveillance of all communications used by terrorists, including e-mails, the Internet, and cell phones.\",\n",
    "    \"From this day forward, any nation that continues to harbor or support terrorism will be regarded by the United States as a hostile regime.\",\n",
    "    \"We are looking out for the Taliban, al Qaeda and other terrorist groups\",\n",
    "    \"We are looking out for al Qaeda and other terrorist groups, especially the Taliban and the muppets\"\n",
    "]\n",
    "\n",
    "def show_hyps(texts):\n",
    "    \n",
    "   \n",
    "    for i, text in enumerate(texts):\n",
    "        print(i, \"#####\")\n",
    "        print(\"custom chunks =>\", [token for token in cnd(text)])\n",
    "        print(cnd(text)._.pairs)\n",
    "        print('-----')\n",
    "\n",
    "show_hyps(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with a Full Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are looking for terrorist groups, such as the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, such, as, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "such_as => []\n",
      "----------\n",
      "we are looking for terrorist groups, known as the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, known, as, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "known_as => []\n",
      "----------\n",
      "we are looking for terrorist groups, including the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, including, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "including => []\n",
      "----------\n",
      "we are looking for terrorist groups, especially the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, especially, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "especially => []\n",
      "----------\n",
      "we are looking for terrorist groups, like the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, like, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "like => []\n",
      "----------\n",
      "we are looking for terrorist groups, mainly the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, mainly, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "mainly => []\n",
      "----------\n",
      "we are looking for terrorist groups, mostly the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, mostly, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "mostly => []\n",
      "----------\n",
      "we are looking for terrorist groups, notably the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, notably, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "notably => []\n",
      "----------\n",
      "we are looking for terrorist groups, principally the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, principally, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "principally => []\n",
      "----------\n",
      "we are looking for terrorist groups, particularly the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, particularly, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "particularly => []\n",
      "----------\n",
      "we are looking for terrorist groups, in particular the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, in, particular, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "in_particular => []\n",
      "----------\n",
      "we are looking for terrorist groups, except the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, except, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "except => []\n",
      "----------\n",
      "we are looking for terrorist groups, other than the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, other, than, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "other_than => []\n",
      "----------\n",
      "we are looking for terrorist groups, which are similar to the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, which, are, similar, to, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "which_be_similar_to => []\n",
      "----------\n",
      "we are looking for terrorist groups, examples of this being the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, examples of this, being, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "example_of_this_be => []\n",
      "----------\n",
      "we are looking for terrorist groups types the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, types, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "type => []\n",
      "----------\n",
      "we are looking for terrorist groups, whether the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, whether, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "whether => []\n",
      "----------\n",
      "we are looking for terrorist groups, compared to the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, compared, to, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "compare_to => []\n",
      "----------\n",
      "we are looking for terrorist groups, which may include the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, which, may, include, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "which may include => []\n",
      "----------\n",
      "we are looking for such terrorist groups as the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, such, terrorist groups, as, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "such_NOUN_as => []\n",
      "----------\n",
      "we are looking for terrorist groups, the Taliban, al Qeada and Southampton University for instance\n",
      "[we, are, looking, for, terrorist groups, ,, the, Taliban, ,, al Qeada, and, Southampton University, for, instance]\n",
      "for_instance => []\n",
      "----------\n",
      "examples of terrorist groups are the Taliban, al Qeada and Southampton University\n",
      "[examples of terrorist groups, are, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "example of => []\n",
      "----------\n",
      "we are looking for terrorist groups, for example, the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, for, example, ,, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "for_example => []\n",
      "----------\n",
      "we are looking for terrorist groups, e.g. the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, e.g., the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "e.g. => []\n",
      "----------\n",
      "we are looking for terrorist groups, i.e. the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, i.e., the Taliban, ,, al Qeada, and, Southampton University]\n",
      "i.e. => [('ie', terrorist groups, i.e. the Taliban), ('ie', terrorist groups, al Qeada), ('ie', terrorist groups, Southampton University)]\n",
      "----------\n",
      "we are looking for terrorist groups, among them, the Taliban, al Qeada and Southampton University\n",
      "[we, are, looking, for, terrorist groups, ,, among, them, ,, the, Taliban, ,, al Qeada, and, Southampton University]\n",
      "among_-PRON- => []\n",
      "----------\n",
      "25 / 26\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import importlib\n",
    "import hpspacy\n",
    "importlib.reload(hpspacy)\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "file = \"first_docs.json\"\n",
    "hs = hpspacy.HearstPatterns(cnd.nlp, extended = True)\n",
    "\n",
    "with open(os.path.join(dirpath, file), \"r\") as f:\n",
    "    last_docs = json.load(f)\n",
    "\n",
    "total = 0\n",
    "for text in last_docs:\n",
    "    doc = cnd(text[2])\n",
    "    print(doc)\n",
    "    print([t for t in doc])\n",
    "    print(text[0], '=>', doc._.pairs)\n",
    "    if not doc._.pairs: total += 1\n",
    "    print('----------')\n",
    "    \n",
    "print(total, '/', len(last_docs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
