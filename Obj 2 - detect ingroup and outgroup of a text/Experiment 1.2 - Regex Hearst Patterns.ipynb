{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Hearst Patterns\n",
    "---\n",
    "In this experiment we test the utility of Hearst Patterns for detecting the ingroup and outgroup of a text.\n",
    "\n",
    "For this experiment regex is used with code taken from: https://github.com/mmichelsonIF/hearst_patterns_python/blob/master/hearstPatterns/hearstPatterns.py\n",
    "\n",
    "Hypernym relations are semantic relationships between two concepts: C1 is a hypernym of C2 means that C1 categorizes C2 (e.g. “instrument” is a hypernym of “Piano”). For this research, the phrase, \"America has enemies, such as Al Qaeda and the Taliban\" would return the following '[('Al Qaeda', 'enemy'), ('the Taliban', 'enemy')]'. In this example, the categorising term 'enemy' is a hypernym of both 'Al Qaeda' and the 'Taliban'; conversely 'al Qaeda' and 'the Tabliban' are hyponyms of 'enemy'. Using this technique, hypernym terms could be classified as ingroup or outgroup and named entities identified as hyponym terms could be identified as either group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment has not produced any results from the bin Laden text, but has produced some promising results from the Bush text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP_the_evidence -PRON- have gather NP_all_point to NP_a_collection of NP_loosely_affiliate_terrorist_organization know as NP_al_Qaeda .\n",
      "[('al Qaeda', 'loosely affiliate terrorist organization')]\n",
      "NP_terrorist_group like NP_al_Qaeda depend upon NP_the_aid or NP_indifference of NP_government .\n",
      "[('al Qaeda', 'terrorist group')]\n",
      "other NP_close_friend , include NP_Canada , NP_Australia , NP_Germany and NP_France , have pledge NP_force as NP_the_operation unfold .\n",
      "[('Canada', 'close friend'), ('Australia', 'close friend'), ('Germany', 'close friend'), ('France', 'close friend'), ('force', 'the operation')]\n"
     ]
    }
   ],
   "source": [
    "h = HearstPatterns(extended=True, merge = False)\n",
    "\n",
    "true_positives = [\n",
    "    \"The evidence we have gathered all points to a collection of loosely affiliated terrorist organizations known as al Qaeda.\",\n",
    "    \"Terrorist groups like al Qaeda depend upon the aid or indifference of governments.\",\n",
    "    \"Other close friends, including Canada, Australia, Germany and France, have pledged forces as the operation unfolds.\",\n",
    "]\n",
    "             \n",
    "for sentence in true_positives:\n",
    "    print(h.find_hyponyms(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are some false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "NP_terrorist , include NP_e__mail , NP_the_internet , and NP_cell_phone \n",
      "[('e  mail', 'terrorist'), ('the internet', 'terrorist'), ('cell phone', 'terrorist')]\n",
      "-----\n",
      "NP_the_United_States as NP_a_hostile_regime\n",
      "[('the United States', 'a hostile regime')]\n"
     ]
    }
   ],
   "source": [
    "false_positives = [\n",
    "    \"This new law that I sign today will allow surveillance of all communications used by terrorists, including e-mails, the Internet, and cell phones.\",\n",
    "    \"From this day forward, any nation that continues to harbor or support terrorism will be regarded by the United States as a hostile regime.\"\n",
    "]\n",
    "\n",
    "for sentence in false_positives:\n",
    "    print(h.find_hyponyms(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 339 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>File Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hitler</th>\n",
       "      <td>Adolf Hitler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bush</th>\n",
       "      <td>George Bush</td>\n",
       "      <td>14.0</td>\n",
       "      <td>143936.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolstoy</th>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>Martin Luther King</td>\n",
       "      <td>5.0</td>\n",
       "      <td>122815.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laden</th>\n",
       "      <td>Osama bin Laden</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77440.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Totals</th>\n",
       "      <td></td>\n",
       "      <td>24.0</td>\n",
       "      <td>344191.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  Text Count  Word Count  File Size\n",
       "Ref                                                           \n",
       "hitler         Adolf Hitler         0.0         0.0       56.0\n",
       "bush            George Bush        14.0    143936.0       56.0\n",
       "tolstoy         Leo Tolstoy         0.0         0.0       56.0\n",
       "king     Martin Luther King         5.0    122815.0       56.0\n",
       "laden       Osama bin Laden         5.0     77440.0       56.0\n",
       "Totals                             24.0    344191.0      280.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import cndobjects\n",
    "importlib.reload(cndobjects)\n",
    "\n",
    "\n",
    "dirpath = r'C:\\\\Users\\\\Steve\\\\OneDrive - University of Southampton\\\\CNDPipeline\\\\dataset'\n",
    "\n",
    "orators = cndobjects.Dataset(dirpath)\n",
    "\n",
    "orators.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "the following code is taken from: https://github.com/mmichelsonIF/hearst_patterns_python/blob/master/hearstPatterns/test/test_hearstPatterns.py\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spacy.pipeline import merge_noun_chunks\n",
    "from spacy.pipeline import merge_entities\n",
    "\n",
    "\n",
    "class HearstPatterns(object):\n",
    "\n",
    "    def __init__(self, extended=False, merge = False):\n",
    "\n",
    "        self.__adj_stopwords = [\n",
    "            'able', 'available', 'brief', 'certain',\n",
    "            'different', 'due', 'enough', 'especially', 'few', 'fifth',\n",
    "            'former', 'his', 'howbeit', 'immediate', 'important', 'inc',\n",
    "            'its', 'last', 'latter', 'least', 'less', 'likely', \n",
    "            'little', 'mainly', 'many', 'ml', 'more', 'most', 'mostly', 'much', \n",
    "            'my', 'necessary', 'new', 'next', 'non', 'notably', 'old', 'other', \n",
    "            'our', 'ours', 'own', 'particular', 'particularly', 'principally',\n",
    "            'past', 'possible', 'present', 'proud', 'recent', 'same', 'several', \n",
    "            'significant', 'similar', 'such', 'sup', 'sure', 'these', 'those'\n",
    "        ]\n",
    "\n",
    "        # now define the Hearst patterns\n",
    "        # format is <hearst-pattern>, <general-term>\n",
    "        # so, what this means is that if you apply the first pattern,\n",
    "        # the first Noun Phrase (NP)\n",
    "        # is the general one, and the rest are specific NPs\n",
    "        self.__hearst_patterns = [\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?such as (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?know as (NP_\\\\w+ ?(, )?(and |or )?)+)', # added for this experiment\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(such NP_\\\\w+ (, )?as (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?include (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?especially (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '((NP_\\\\w+ ?(, )?)+(and |or )?other NP_\\\\w+)',\n",
    "                'last'\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        if extended:\n",
    "            self.__hearst_patterns.extend([\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?like (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?mainly (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?mostly (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?notably (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?particularly (NP_\\\\w+ ?(, )?(and |or )?)+)', ######\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?principally (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?in particular (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?except (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?other than (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?e.g. (, )?(NP_\\\\w+ ? (, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ \\\\( (e.g.|i.e.) (, )?(NP_\\\\w+ ? (, )?(and |or )?)+'\n",
    "                    '(\\\\. )?\\\\))',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+(, )?i.e. (, )?(NP_\\\\w+ ? (, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    'example of (NP_\\\\w+ (, )?be (NP_\\\\w+ ?(, )?(and |or )?)+)', \n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?for example (, )?(NP_\\\\w+ ?(, )?(and |or )?)+)', #####\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?which be similar to (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?example of this be (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?whether (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?compare to (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?among -PRON- (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?type (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )? (NP_\\\\w+ ? (, )?(and |or )?)+ for instance)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?which may include (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?any other NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?some other NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?be a NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "\n",
    "#                 (\n",
    "#                     'such (NP_\\\\w+ (, )?as (NP_\\\\w+ ? (, )?(and |or )?)+)',\n",
    "#                     'first'\n",
    "#                 ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?like other NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?one of the NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?one of these NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?one of those NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?be example of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which be call NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which be name NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? a kind of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? kind of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? form of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which look like NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which sound like NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )? NP_\\\\w+ type)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '(compare (NP_\\\\w+ ?(, )?)+(and |or )?with NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?as NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? sort of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                )\n",
    "            ])\n",
    "\n",
    "        self.__spacy_nlp = spacy.load('en_core_web_sm')\n",
    "            \n",
    "\n",
    "    def chunk(self, rawtext):\n",
    "        doc = self.__spacy_nlp(rawtext)\n",
    "        chunks = []\n",
    "        for sentence in doc.sents:\n",
    "            sentence_text = sentence.lemma_\n",
    "            for chunk in sentence.noun_chunks:\n",
    "                if chunk.lemma_.lower() == \"example\":\n",
    "                    start = chunk.start\n",
    "                    pre_token = sentence[start - 1].lemma_.lower()\n",
    "                    post_token = sentence[start + 1].lemma_.lower()\n",
    "                    if start > 0 and\\\n",
    "                            (pre_token == \"for\" or post_token == \"of\"):\n",
    "                        continue\n",
    "                if chunk.lemma_.lower() == \"type\":\n",
    "                    continue\n",
    "                chunk_arr = []\n",
    "                replace_arr = []\n",
    "                # print(\"chunk:\", chunk)\n",
    "                for token in chunk:\n",
    "                    if token.lemma_ in self.__adj_stopwords + [\"i.e.\", \"e.g.\"]:\n",
    "                        continue\n",
    "                    chunk_arr.append(token.lemma_)\n",
    "                    # Remove punctuation and stopword adjectives\n",
    "                    # (generally quantifiers of plurals)\n",
    "                    if token.lemma_.isalnum():\n",
    "                        replace_arr.append(token.lemma_)\n",
    "                    else:\n",
    "                        replace_arr.append(''.join(\n",
    "                            char for char in token.lemma_ if char.isalnum()\n",
    "                        ))\n",
    "                if len(chunk_arr) == 0:\n",
    "                    chunk_arr.append(chunk[-1].lemma_)\n",
    "                chunk_lemma = ' '.join(chunk_arr)\n",
    "                # print(chunk_lemma)\n",
    "                replacement_value = 'NP_' + '_'.join(replace_arr)\n",
    "                if chunk_lemma:\n",
    "                    sentence_text = re.sub(r'\\b%s\\b' % re.escape(chunk_lemma),\n",
    "                                           r'%s' % replacement_value,\n",
    "                                           sentence_text)\n",
    "            chunks.append(sentence_text)\n",
    "        return chunks\n",
    "\n",
    "    \"\"\"\n",
    "        This is the main entry point for this code.\n",
    "        It takes as input the rawtext to process and returns a list\n",
    "        of tuples (specific-term, general-term)\n",
    "        where each tuple represents a hypernym pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    def find_hyponyms(self, rawtext):\n",
    "\n",
    "        hyponyms = []\n",
    "        np_tagged_sentences = self.chunk(rawtext)\n",
    "\n",
    "        for sentence in np_tagged_sentences:\n",
    "            # two or more NPs next to each other should be merged\n",
    "            # into a single NP, it's a chunk error\n",
    "            \n",
    "            #hyponyms.append(sentence)\n",
    "\n",
    "            for (hearst_pattern, parser) in self.__hearst_patterns:\n",
    "                matches = re.search(hearst_pattern, sentence)\n",
    "                if matches:\n",
    "                    match_str = matches.group(0)\n",
    "\n",
    "                    nps = [a for a in match_str.split() if a.startswith(\"NP_\")]\n",
    "\n",
    "                    if parser == \"first\":\n",
    "                        general = nps[0]\n",
    "                        specifics = nps[1:]\n",
    "                    else:\n",
    "                        general = nps[-1]\n",
    "                        specifics = nps[:-1]\n",
    "\n",
    "                    for i in range(len(specifics)):\n",
    "                        pair = (\n",
    "                            self.clean_hyponym_term(specifics[i]),\n",
    "                            self.clean_hyponym_term(general)\n",
    "                        )\n",
    "                        # reduce duplicates\n",
    "                        if pair not in hyponyms:\n",
    "                            hyponyms.append(pair)\n",
    "\n",
    "        return hyponyms\n",
    "\n",
    "    def clean_hyponym_term(self, term):\n",
    "        # good point to do the stemming or lemmatization\n",
    "        return term.replace(\"NP_\", \"\").replace(\"_\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h = HearstPatterns(extended=True, merge = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[('an exceptional man', 'passenger'), ('al Qaeda', 'loosely affiliate terrorist organization'), ('woman', 'civilian'), ('child', 'civilian'), ('the Egyptian Islamic Jihad', 'country'), ('the Islamic Movement', 'country'), ('Afghanistan', 'place'), ('american citizen', 'all foreign national'), ('Egypt', 'muslim country'), ('Saudi Arabia', 'muslim country'), ('Jordan', 'muslim country'), ('the will', 'every value'), ('the United States', 'a hostile regime'), ('terrorism', 'a threat')]\n"
     ]
    }
   ],
   "source": [
    "hyponyms = h.find_hyponyms(orators[\"bush\"][4])\n",
    "print(len(hyponyms))\n",
    "print(hyponyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(orators[\"bush\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "h = HearstPatterns(extended=True, merge = False)\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "file = \"last_docs.json\"\n",
    "\n",
    "with open(os.path.join(dirpath, file), \"r\") as f:\n",
    "    last_docs = json.load(f)\n",
    "\n",
    "for doc in last_docs:\n",
    "    hyponyms = h.find_hyponyms(doc[1])\n",
    "    #if len(hyponyms[1:]) != 3:\n",
    "    print(doc[1])\n",
    "    print(doc[0], '=>', hyponyms)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The younger ones occupied themselves as before, some playing cards (there was plenty of money, though there was no food), some with more innocent games, such as quoits and skittles\n",
      "True\n",
      "such_as => [('quoit', 'innocent game'), ('skittle', 'innocent game')]\n",
      "----------\n",
      "The trench itself was the room, in which the lucky ones, such as the squadron commander, had a board, lying on piles at the end opposite the entrance, to serve as a table.\n",
      "True\n",
      "such_as => [('the squadron commander', 'the lucky one')]\n",
      "----------\n",
      "Through the hard century-old bark, even where there were no twigs, leaves had sprouted such as one could hardly believe the old veteran could have produced.\n",
      "False\n",
      "such_as => []\n",
      "----------\n",
      "Religion alone can explain to us what without its help man cannot comprehend: why, for what cause, kind and noble beings able to find happiness in life—not merely harming no one but necessary to the happiness of others—are called away to God, while cruel, useless, harmful persons, or such as are a burden to themselves and to others, are left living\n",
      "False\n",
      "such_as => []\n",
      "----------\n",
      "The youthful little Princess Bolkónskaya, known as la femme la plus séduisante de Pétersbourg\n",
      "True\n",
      "known_as => []\n",
      "----------\n",
      "The prince’s house did not belong to what is known as fashionable society, but his little circle—though not much talked about in town—was one it was more flattering to be received in than any other.\n",
      "False\n",
      "known_as => []\n",
      "----------\n",
      "And Prince Hippolyte began to tell his story in such Russian as a Frenchman would speak after spending about a year in Russia.\n",
      "False\n",
      "such_NOUN_as => [('a Frenchman', 'Russian'), ('Russian', 'a Frenchman')]\n",
      "----------\n",
      "at such a moment as this one must think of everything\n",
      "False\n",
      "such_NOUN_as => [('this one', 'a moment'), ('a moment', 'this one')]\n",
      "----------\n",
      "Come, I will go with you. Try to weep, nothing gives such relief as tears.\n",
      "True\n",
      "such_NOUN_as => [('tear', 'relief'), ('relief', 'tear')]\n",
      "----------\n",
      "It uplifts the soul to see such men as the old count and his worthy son\n",
      "True\n",
      "such_NOUN_as => []\n",
      "----------\n",
      "others simply enjoyed hearing how the master talked, while the cleverest among them, including the chief steward, understood from this speech how they could best handle the master for their own ends\n",
      "True\n",
      "include => []\n",
      "----------\n",
      "On the twenty-ninth of May Napoleon left Dresden, where he had spent three weeks surrounded by a court that included princes, dukes, kings, and even an emperor\n",
      "True\n",
      "include => []\n",
      "----------\n",
      "Pierre respected this class of Brothers to which the elder ones chiefly belonged, including, Pierre thought, Joseph Alexéevich himself, but he did not share their interests.\n",
      "False\n",
      "include => []\n",
      "----------\n",
      "About twenty people were present, including Dólokhov and Denísov\n",
      "False\n",
      "include => []\n",
      "----------\n",
      "They are regular brigands, especially Dólokhov\n",
      "True\n",
      "especially => [('Dólokhov', 'regular brigand')]\n",
      "----------\n",
      "But he did not run after the unmarried girls, especially the rich heiresses who were most of them plain.\n",
      "True\n",
      "especially => [('the rich heiress', 'the unmarried girl'), ('who', 'the unmarried girl')]\n",
      "----------\n",
      "The faces of these young people, especially those who were military men, bore that expression of condescending respect for their elders which seems to say to the older generation, “We are prepared to respect and honor you, but all the same remember that the future belongs to us.\n",
      "True\n",
      "especially => []\n",
      "----------\n",
      "Her pretty little upper lip, on which a delicate dark down was just perceptible, was too short for her teeth, but it lifted all the more sweetly, and was especially charming when she occasionally drew it down to meet the lower lip\n",
      "False\n",
      "especially => []\n",
      "----------\n",
      "The story was very pretty and interesting, especially at the point where the rivals suddenly recognized one another; and the ladies looked agitated.\n",
      "False\n",
      "especially => []\n",
      "----------\n",
      "and the vicomte was served up to the company in the choicest and most advantageous style, like a well-garnished joint of roast beef on a hot dish.\n",
      "True\n",
      "like => []\n",
      "----------\n",
      "It is only necessary for one powerful nation like Russia — barbaric as she is said to be — to place herself disinterestedly at the head of an alliance having for its object the maintenance of the balance of power of Europe, and it would save the world!\n",
      "True\n",
      "like => [('Russia', 'one powerful nation')]\n",
      "----------\n",
      "It was evident that he did not like the vicomte and was aiming his remarks at him, though without looking at him.\n",
      "False\n",
      "like => []\n",
      "----------\n",
      "You treat me like an invalid or a child. I see it all! Did you behave like that six months ago?\n",
      "False\n",
      "like => []\n",
      "----------\n",
      "Natásha, that winter, had for the first time begun to sing seriously, mainly because Denísov so delighted in her singing.\n",
      "False\n",
      "mainly => []\n",
      "----------\n",
      "Moreover, he could see by her manners that she was one of those women—mostly mothers—who, having once made up their minds, will not rest until they have gained their end, and are prepared if necessary to go on insisting day after day and hour after hour, and even to make scenes.\n",
      "True\n",
      "mostly => []\n",
      "----------\n",
      "All the members of the lodges were men Pierre knew in ordinary life, and it was difficult for him to regard them merely as Brothers in Freemasonry and not as Prince B. or Iván Vasílevich D., whom he knew in society mostly as weak and insignificant men\n",
      "False\n",
      "mostly => []\n",
      "----------\n",
      "\n",
      "None\n",
      "notably => []\n",
      "----------\n",
      "L'amour which the Frenchman worshiped consisted principally in the unnaturalness of his relation to the woman and in a combination of incongruities giving the chief charm to the feeling.\n",
      "False\n",
      "principally => []\n",
      "----------\n",
      "While waiting for the announcement of his appointment to the committee Prince Andrew looked up his former acquaintances, particularly those he knew to be in power and whose aid he might need.\n",
      "False\n",
      "particularly => []\n",
      "----------\n",
      "Rostóv was particularly in need of money now that the troops, after their active service, were stationed near Olmütz and the camp swarmed with well-provisioned sutlers and Austrian Jews offering all sorts of tempting wares.\n",
      "False\n",
      "particularly => []\n",
      "----------\n",
      "The three great sorrows of his life held his attention in particular: his love for a woman, his father’s death, and the French invasion which had overrun half Russia.\n",
      "True\n",
      "in_particular => []\n",
      "----------\n",
      "And as he waved his arms to impersonate the policeman, his portly form again shook with a deep ringing laugh, the laugh of one who always eats well and, in particular, drinks well.\n",
      "False\n",
      "in_particular => []\n",
      "----------\n",
      "She was not in love with anyone in particular, but with everyone\n",
      "False\n",
      "in_particular => []\n",
      "----------\n",
      "There was now no one in the reception room except Prince Vasíli and the eldest princess, who were sitting under the portrait of Catherine the Great and talking eagerly\n",
      "True\n",
      "except => [('Prince Vasíli', 'the reception room'), ('the eld princess', 'the reception room'), ('who', 'the reception room')]\n",
      "----------\n",
      "He made use of every kind of mental device, except analogy, and passed too boldly, it seemed to Prince Andrew, from one to another.\n",
      "True\n",
      "except => [('analogy', 'mental device')]\n",
      "----------\n",
      "There was really nothing to be seen in front except a barren descent hidden by dense mist.\n",
      "False\n",
      "except => [('a barren descent', 'front')]\n",
      "----------\n",
      "Kutúzov no one spoke of, except some who abused him in whispers, calling him a court weathercock and an old satyr.\n",
      "False\n",
      "except => []\n",
      "----------\n",
      "\n",
      "None\n",
      "other_than => []\n",
      "----------\n",
      "In front was Glory, which was similar to those threads but rather thicker.\n",
      "True\n",
      "which_be_similar_to => []\n",
      "----------\n",
      "\n",
      "None\n",
      "example_of_this_be => []\n",
      "----------\n",
      "Countess Bezúkhova was present among other Russian ladies who had followed the sovereign from Petersburg to Vílna and eclipsed the refined Polish ladies by her massive, so-called Russian type of beauty\n",
      "False\n",
      "type => []\n",
      "----------\n",
      "When we do not at all understand the cause of an action, whether a crime, a good action, or even one that is simply nonmoral, we ascribe a greater amount of freedom to it.\n",
      "True\n",
      "whether => []\n",
      "----------\n",
      "She could not fathom whether it was curiosity, devotion, gratitude, or apprehension and distrust—but the expression on all the faces was identical.\n",
      "False\n",
      "whether => []\n",
      "----------\n",
      "He opened his eyes, hoping to see how the struggle of the Frenchmen with the gunners ended, whether the red-haired gunner had been killed or not and whether the cannon had been captured or saved.\n",
      "False\n",
      "weather => []\n",
      "----------\n",
      "\n",
      "None\n",
      "compare_to => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which may include => []\n",
      "----------\n",
      "\n",
      "None\n",
      "for_instance => []\n",
      "----------\n",
      "But the most amazing example of the ineffectiveness of the orders given by the authorities at that time was Napoleon’s attempt to stop the looting and re-establish discipline.\n",
      "False\n",
      "example_of => []\n",
      "----------\n",
      "and so, led astray by pride, losing sight of this aim, we occupy ourselves either with the mystery which in our impurity we are unworthy to receive, or seek the reformation of the human race while ourselves setting an example of baseness and profligacy\n",
      "False\n",
      "example_of => []\n",
      "----------\n",
      "To the defenders of the laws of Copernicus and Newton, to Voltaire for example, it seemed that the laws of astronomy destroyed religion, and he utilized the law of gravitation as a weapon against religion.\n",
      "False\n",
      "for_example => [('gravitation', 'a weapon')]\n",
      "----------\n",
      "Several persons, among them the elderly lady and Anna Pávlovna, did however smile.\n",
      "True\n",
      "among_-PRON- => []\n",
      "----------\n",
      "As the bearers, among whom was Anna Mikháylovna, passed the young man he caught a momentary glimpse between their heads and backs of the dying man’s high, stout, uncovered chest and powerful shoulders, raised by those who were holding him under the armpits, and of his gray, curly, leonine head.\n",
      "True\n",
      "among_-PRON- => []\n",
      "----------\n",
      "I am fond of you, especially as you are the one live man among our whole set\n",
      "False\n",
      "among_-PRON- => []\n",
      "----------\n",
      "This young man, of whom I spoke to you last summer, is so noble-minded and full of that real youthfulness which one seldom finds nowadays among our old men of twenty and, particularly, he is so frank and has so much heart.\n",
      "False\n",
      "among_-PRON- => []\n",
      "----------\n",
      "\n",
      "None\n",
      "e.g. => []\n",
      "----------\n",
      "\n",
      "None\n",
      "i.e.. => []\n",
      "----------\n",
      "Pierre went home, but Rostóv with Dólokhov and Denísov stayed on at the club till late, listening to the gypsies and other singers\n",
      "True\n",
      "other => [('the gypsy', 'singer')]\n",
      "----------\n",
      "That night the doors were again broken open, the padlocks smashed, the books mutilated, and other disorders perpetrated.\n",
      "True\n",
      "other => []\n",
      "----------\n",
      "It is only to prevent some Pugachëv or other from killing my children and yours, and Arakchéev from sending me off to some Military Settlement.\n",
      "False\n",
      "other => []\n",
      "----------\n",
      "At that instant the sun began to hide behind the clouds, and other stretchers came into view before Rostóv.\n",
      "False\n",
      "other => [('the cloud', 'stretcher')]\n",
      "----------\n",
      "Tíkhon knew that neither the son’s arrival nor any other unusual event must be allowed to disturb the appointed order of the day.\n",
      "False\n",
      "any_other => []\n",
      "----------\n",
      "Amid the general rumble, the groans and voices of the wounded were more distinctly heard than any other sound in the darkness of the night.\n",
      "False\n",
      "any_other => []\n",
      "----------\n",
      "There was about him something of Weyrother, Mack, and Schmidt, and many other German theorist-generals whom Prince Andrew had seen in 1805, but he was more typical than any of them.\n",
      "True\n",
      "many_other => []\n",
      "----------\n",
      "there were up to that time very few, but she mentioned Napoleon and some other exalted personages\n",
      "True\n",
      "some_other => []\n",
      "----------\n",
      "Each historian, according to his view of what constitutes a nation’s progress, looks for these conditions in the greatness, wealth, freedom, or enlightenment of citizens of France or some other country.\n",
      "True\n",
      "some_other => []\n",
      "----------\n",
      "While Russia was well, a foreigner could serve her and be a splendid minister\n",
      "False\n",
      "be_a => []\n",
      "----------\n",
      "All the well-known people of that period, from Alexander and Napoleon to Madame de Staël, Photius, Schelling, Fichte, Chateaubriand, and the rest, pass before their stern judgment seat and are acquitted or condemned according to whether they conduced to progress or to reaction.\n",
      "False\n",
      "be_a => []\n",
      "----------\n",
      "\n",
      "None\n",
      "like_other => []\n",
      "----------\n",
      "On his return to Moscow from the army, Nicholas Rostóv was welcomed by his home circle as the best of sons, a hero, and their darling Nikólenka; by his relations as a charming, attractive, and polite young man; by his acquaintances as a handsome lieutenant of hussars, a good dancer, and one of the best matches in the city.\n",
      "True\n",
      "one_of_the => []\n",
      "----------\n",
      "A door of one of the inner rooms opened and one of the princesses, the count’s niece, entered with a cold, stern face.\n",
      "False\n",
      "one_of_the => []\n",
      "----------\n",
      "Of the two soups he chose turtle with savory patties and went on to the game without omitting a single dish or one of the wines.\n",
      "False\n",
      "one_of_the => []\n",
      "----------\n",
      "She loved and knew Prince Andrew, he loved her only, and was to come one of these days and take her.\n",
      "True\n",
      "one_of_these => []\n",
      "----------\n",
      "Prince Andrew was one of those rare staff officers whose chief interest lay in the general progress of the war.\n",
      "True\n",
      "one_of_those => [('whose chief interest', 'rare staff officer')]\n",
      "----------\n",
      "\n",
      "None\n",
      "be_example_of => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_be_call => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_be_name => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_look_lile => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_sound_like => []\n",
      "----------\n",
      "Casting a rapid glance at all those in the room and noticing the count’s confessor there, she glided up to him with a sort of amble, not exactly bowing yet seeming to grow suddenly smaller, and respectfully received the blessing first of one and then of another priest.\n",
      "False\n",
      "sort_of => []\n",
      "----------\n",
      "He felt it awkward to attract everyone’s attention and to be considered a lucky man and, with his plain face, to be looked on as a sort of Paris possessed of a Helen.\n",
      "False\n",
      "sort_of => []\n",
      "----------\n",
      "/'Yes, I feel a kind of oppression,/' she said in reply to the prince’s question as to how she felt.\n",
      "False\n",
      "a_kind_of => []\n",
      "----------\n",
      "Yet in this very repugnance to all his circumstances Pierre found a kind of tantalizing satisfaction.\n",
      "False\n",
      "a_kind_of => []\n",
      "----------\n",
      "Life was cheaper because it was circumscribed: that most expensive luxury, the kind of life that can be changed at any moment, was no longer his nor did he wish for it.\n",
      "False\n",
      "kind_of => []\n",
      "----------\n",
      "Secondly, it is assumed that the goal toward which humanity is being led is known to the historians: to one of them this goal is the greatness of the Roman, Spanish, or French realm; to another it is liberty, equality, and a certain kind of civilization of a small corner of the world called Europe.\n",
      "False\n",
      "kind_of => []\n",
      "----------\n",
      "\n",
      "None\n",
      "form_of => []\n",
      "----------\n",
      "\n",
      "None\n",
      "as => []\n",
      "----------\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "h = HearstPatterns(extended=True, merge = False)\n",
    "\n",
    "dirpath = r\"C:\\Users\\Steve\\OneDrive - University of Southampton\\CNDPipeline\\dataset\\Tolstoy\"\n",
    "file = \"warandpeace_testdata.json\"\n",
    "\n",
    "with open(os.path.join(dirpath, file), \"r\") as f:\n",
    "    docs = json.load(f)\n",
    "    \n",
    "for doc in docs:\n",
    "    hyponyms = h.find_hyponyms(doc[2])\n",
    "    #if len(hyponyms[1:]) != 3:\n",
    "    print(doc[2])\n",
    "    print(doc[1])\n",
    "    print(doc[0], '=>', hyponyms)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: test_hyponym_finder (__main__.TestHearstPatterns)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-14-71766177d2a3>\", line 47, in test_hyponym_finder\n",
      "    self.assertEqual(tuple(map(str.lower, hyps7[0])), (\"apple\", \"fruit\"))\n",
      "IndexError: list index out of range\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.191s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestHearstPatterns(unittest.TestCase):\n",
    "\n",
    "    def test_hyponym_finder(self):\n",
    "        h = HearstPatterns(extended=True)\n",
    "\n",
    "        # H1\n",
    "        hyps1 = h.find_hyponyms(\"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\")\n",
    "\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[0])), (\"red eye\", \"symptom\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[1])), (\"ocular pain\", \"symptom\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[2])), (\"visual acuity\", \"symptom\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[3])), (\"photophobia\", \"symptom\"))\n",
    "\n",
    "        # H2\n",
    "        hyps2 = h.find_hyponyms(\"There are works by such authors as Herrick, Goldsmith, and Shakespeare.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps2[0])), (\"herrick\", \"author\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps2[1])), (\"goldsmith\", \"author\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps2[2])), (\"shakespeare\", \"author\"))\n",
    "\n",
    "        # H3\n",
    "        hyps3 = h.find_hyponyms(\"There were bruises, lacerations, or other injuries were not prevalent.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps3[0])), (\"bruise\", \"injury\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps3[1])), (\"laceration\", \"injury\"))\n",
    "\n",
    "        # H4\n",
    "        hyps4 = h.find_hyponyms(\"common law countries, including Canada, Australia, and England enjoy toast.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps4[0])), (\"canada\", \"common law country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps4[1])), (\"australia\", \"common law country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps4[2])), (\"england\", \"common law country\"))\n",
    "\n",
    "        # H5\n",
    "        hyps5 = h.find_hyponyms(\"Many countries, especially France, England and Spain also enjoy toast.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps5[0])), (\"france\", \"country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps5[1])), (\"england\", \"country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps5[2])), (\"spain\", \"country\"))\n",
    "\n",
    "        # H2\n",
    "        hyps6 = h.find_hyponyms(\"There are such benefits as postharvest losses reduction, food increase and soil fertility improvement.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps6[0])), (\"postharvest loss reduction\", \"benefit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps6[1])), (\"food increase\", \"benefit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps6[2])), (\"soil fertility improvement\", \"benefit\"))\n",
    "\n",
    "        # H'1\n",
    "        hyps7 = h.find_hyponyms(\"Fruits, i.e. , apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        hyps7 = h.find_hyponyms(\"Fruits, e.g. apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        # H'2\n",
    "\n",
    "        hyps10 = h.find_hyponyms(\"Fruits (e.g. apples, bananas, oranges and peaches.)\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        hyps10 = h.find_hyponyms(\"Fruits (i.e. apples, bananas, oranges and peaches.)\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        # H'3\n",
    "        hyps8 = h.find_hyponyms(\"Fruits, for example apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        # H'4\n",
    "        hyps9 = h.find_hyponyms(\"Fruits, which may include apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_hyponym_finder (__main__.TestHearstPatterns)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-88c88a93b418>\", line 14, in test_hyponym_finder\n",
      "    self.assertEqual(hyps2[0], (\"herrick\", \"author\"))\n",
      "AssertionError: Tuples differ: ('Herrick', 'author') != ('herrick', 'author')\n",
      "\n",
      "First differing element 0:\n",
      "'Herrick'\n",
      "'herrick'\n",
      "\n",
      "- ('Herrick', 'author')\n",
      "?   ^\n",
      "\n",
      "+ ('herrick', 'author')\n",
      "?   ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.183s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestHearstPatterns(unittest.TestCase):\n",
    "\n",
    "    def test_hyponym_finder(self):\n",
    "        h = HearstPatterns()\n",
    "        hyps1 =  h.find_hyponyms(\"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\")\n",
    "        self.assertEqual(hyps1[0], (\"red eye\", \"symptom\"))\n",
    "        self.assertEqual(hyps1[1], (\"ocular pain\", \"symptom\"))\n",
    "        self.assertEqual(hyps1[2], (\"visual acuity\", \"symptom\"))\n",
    "        self.assertEqual(hyps1[3], (\"photophobia\", \"symptom\"))\n",
    "\n",
    "        hyps2 = h.find_hyponyms(\"There are works by such authors as Herrick, Goldsmith, and Shakespeare.\")\n",
    "        self.assertEqual(hyps2[0], (\"herrick\", \"author\"))\n",
    "        self.assertEqual(hyps2[1], (\"goldsmith\", \"author\"))\n",
    "        self.assertEqual(hyps2[2], (\"shakespeare\", \"author\"))\n",
    "\n",
    "        hyps3 = h.find_hyponyms(\"There were bruises, lacerations, or other injuries were not prevalent.\")\n",
    "        self.assertEqual(hyps3[0], (\"bruise\", \"injury\"))\n",
    "        self.assertEqual(hyps3[1], (\"laceration\", \"injury\"))\n",
    "\n",
    "        hyps4 =  h.find_hyponyms(\"common law countries, including Canada, Australia, and England enjoy toast.\")\n",
    "        self.assertEqual(hyps4[0], (\"canada\", \"common law country\"))\n",
    "        self.assertEqual(hyps4[1], (\"australia\", \"common law country\"))\n",
    "        self.assertEqual(hyps4[2], (\"england\", \"common law country\"))\n",
    "\n",
    "        hyps5 = h.find_hyponyms(\"Many countries, especially France, England and Spain also enjoy toast.\")\n",
    "        self.assertEqual(hyps5[0], (\"france\", \"country\"))\n",
    "        self.assertEqual(hyps5[1], (\"england\", \"country\"))\n",
    "        self.assertEqual(hyps5[2], (\"spain\", \"country\"))\n",
    "\n",
    "        hyps6 = h.find_hyponyms(\"There are such benefits as postharvest losses reduction, food increase and soil fertility improvement.\")\n",
    "        self.assertEqual(hyps6[0], (\"postharvest loss reduction\", \"benefit\"))\n",
    "        self.assertEqual(hyps6[1], (\"food increase\", \"benefit\"))\n",
    "        self.assertEqual(hyps6[2], (\"soil fertility improvement\", \"benefit\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
