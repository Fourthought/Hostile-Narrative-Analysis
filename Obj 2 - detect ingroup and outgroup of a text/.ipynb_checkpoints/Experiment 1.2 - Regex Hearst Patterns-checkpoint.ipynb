{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Hearst Patterns\n",
    "---\n",
    "In this experiment we test the utility of Hearst Patterns for detecting the ingroup and outgroup of a text.\n",
    "\n",
    "For this experiment regex is used with code taken from: https://github.com/mmichelsonIF/hearst_patterns_python/blob/master/hearstPatterns/hearstPatterns.py\n",
    "\n",
    "Hypernym relations are semantic relationships between two concepts: C1 is a hypernym of C2 means that C1 categorizes C2 (e.g. “instrument” is a hypernym of “Piano”). For this research, the phrase, \"America has enemies, such as Al Qaeda and the Taliban\" would return the following '[('Al Qaeda', 'enemy'), ('the Taliban', 'enemy')]'. In this example, the categorising term 'enemy' is a hypernym of both 'Al Qaeda' and the 'Taliban'; conversely 'al Qaeda' and 'the Tabliban' are hyponyms of 'enemy'. Using this technique, hypernym terms could be classified as ingroup or outgroup and named entities identified as hyponym terms could be identified as either group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This experiment has not produced any results from the bin Laden text, but has produced some promising results from the Bush text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NP_the_evidence -PRON- have gather NP_all_point to NP_a_collection of NP_loosely_affiliate_terrorist_organization know as NP_al_Qaeda .\n",
      "[('al Qaeda', 'loosely affiliate terrorist organization')]\n",
      "NP_terrorist_group like NP_al_Qaeda depend upon NP_the_aid or NP_indifference of NP_government .\n",
      "[('al Qaeda', 'terrorist group')]\n",
      "other NP_close_friend , include NP_Canada , NP_Australia , NP_Germany and NP_France , have pledge NP_force as NP_the_operation unfold .\n",
      "[('Canada', 'close friend'), ('Australia', 'close friend'), ('Germany', 'close friend'), ('France', 'close friend'), ('force', 'the operation')]\n"
     ]
    }
   ],
   "source": [
    "h = HearstPatterns(extended=True, merge = False)\n",
    "\n",
    "true_positives = [\n",
    "    \"The evidence we have gathered all points to a collection of loosely affiliated terrorist organizations known as al Qaeda.\",\n",
    "    \"Terrorist groups like al Qaeda depend upon the aid or indifference of governments.\",\n",
    "    \"Other close friends, including Canada, Australia, Germany and France, have pledged forces as the operation unfolds.\",\n",
    "]\n",
    "             \n",
    "for sentence in true_positives:\n",
    "    print(h.find_hyponyms(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are some false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----\n",
      "NP_terrorist , include NP_e__mail , NP_the_internet , and NP_cell_phone \n",
      "[('e  mail', 'terrorist'), ('the internet', 'terrorist'), ('cell phone', 'terrorist')]\n",
      "-----\n",
      "NP_the_United_States as NP_a_hostile_regime\n",
      "[('the United States', 'a hostile regime')]\n"
     ]
    }
   ],
   "source": [
    "false_positives = [\n",
    "    \"This new law that I sign today will allow surveillance of all communications used by terrorists, including e-mails, the Internet, and cell phones.\",\n",
    "    \"From this day forward, any nation that continues to harbor or support terrorism will be regarded by the United States as a hostile regime.\"\n",
    "]\n",
    "\n",
    "for sentence in false_positives:\n",
    "    print(h.find_hyponyms(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 339 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text Count</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>File Size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hitler</th>\n",
       "      <td>Adolf Hitler</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bush</th>\n",
       "      <td>George Bush</td>\n",
       "      <td>14.0</td>\n",
       "      <td>143936.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolstoy</th>\n",
       "      <td>Leo Tolstoy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <td>Martin Luther King</td>\n",
       "      <td>5.0</td>\n",
       "      <td>122815.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laden</th>\n",
       "      <td>Osama bin Laden</td>\n",
       "      <td>5.0</td>\n",
       "      <td>77440.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Totals</th>\n",
       "      <td></td>\n",
       "      <td>24.0</td>\n",
       "      <td>344191.0</td>\n",
       "      <td>280.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  Text Count  Word Count  File Size\n",
       "Ref                                                           \n",
       "hitler         Adolf Hitler         0.0         0.0       56.0\n",
       "bush            George Bush        14.0    143936.0       56.0\n",
       "tolstoy         Leo Tolstoy         0.0         0.0       56.0\n",
       "king     Martin Luther King         5.0    122815.0       56.0\n",
       "laden       Osama bin Laden         5.0     77440.0       56.0\n",
       "Totals                             24.0    344191.0      280.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import cndobjects\n",
    "importlib.reload(cndobjects)\n",
    "\n",
    "\n",
    "dirpath = r'C:\\\\Users\\\\Steve\\\\OneDrive - University of Southampton\\\\CNDPipeline\\\\dataset'\n",
    "\n",
    "orators = cndobjects.Dataset(dirpath)\n",
    "\n",
    "orators.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\"\"\"\n",
    "the following code is taken from: https://github.com/mmichelsonIF/hearst_patterns_python/blob/master/hearstPatterns/test/test_hearstPatterns.py\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import string\n",
    "import spacy\n",
    "from spacy.pipeline import merge_noun_chunks\n",
    "from spacy.pipeline import merge_entities\n",
    "\n",
    "\n",
    "class HearstPatterns(object):\n",
    "\n",
    "    def __init__(self, extended=False, merge = False):\n",
    "\n",
    "        self.__adj_stopwords = [\n",
    "            'able', 'available', 'brief', 'certain',\n",
    "            'different', 'due', 'enough', 'especially', 'few', 'fifth',\n",
    "            'former', 'his', 'howbeit', 'immediate', 'important', 'inc',\n",
    "            'its', 'last', 'latter', 'least', 'less', 'likely', \n",
    "            'little', 'mainly', 'many', 'ml', 'more', 'most', 'mostly', 'much', \n",
    "            'my', 'necessary', 'new', 'next', 'non', 'notably', 'old', 'other', \n",
    "            'our', 'ours', 'own', 'particular', 'particularly', 'principally',\n",
    "            'past', 'possible', 'present', 'proud', 'recent', 'same', 'several', \n",
    "            'significant', 'similar', 'such', 'sup', 'sure', 'these', 'those'\n",
    "        ]\n",
    "\n",
    "        # now define the Hearst patterns\n",
    "        # format is <hearst-pattern>, <general-term>\n",
    "        # so, what this means is that if you apply the first pattern,\n",
    "        # the first Noun Phrase (NP)\n",
    "        # is the general one, and the rest are specific NPs\n",
    "        self.__hearst_patterns = [\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?such as (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?know as (NP_\\\\w+ ?(, )?(and |or )?)+)', # added for this experiment\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(such NP_\\\\w+ (, )?as (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?include (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '(NP_\\\\w+ (, )?especially (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                'first'\n",
    "            ),\n",
    "            (\n",
    "                '((NP_\\\\w+ ?(, )?)+(and |or )?other NP_\\\\w+)',\n",
    "                'last'\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "        if extended:\n",
    "            self.__hearst_patterns.extend([\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?like (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?mainly (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?mostly (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?notably (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?particularly (NP_\\\\w+ ?(, )?(and |or )?)+)', ######\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?principally (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?in particular (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?except (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?other than (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?e.g. (, )?(NP_\\\\w+ ? (, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ \\\\( (e.g.|i.e.) (, )?(NP_\\\\w+ ? (, )?(and |or )?)+'\n",
    "                    '(\\\\. )?\\\\))',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+(, )?i.e. (, )?(NP_\\\\w+ ? (, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    'example of (NP_\\\\w+ (, )?be (NP_\\\\w+ ?(, )?(and |or )?)+)', \n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?for example (, )?(NP_\\\\w+ ?(, )?(and |or )?)+)', #####\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?which be similar to (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?example of this be (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?whether (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?compare to (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?among -PRON- (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?type (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )? (NP_\\\\w+ ? (, )?(and |or )?)+ for instance)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '(NP_\\\\w+ (, )?which may include (NP_\\\\w+ ?(, )?(and |or )?)+)',\n",
    "                    'first'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?any other NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?some other NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?be a NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "\n",
    "#                 (\n",
    "#                     'such (NP_\\\\w+ (, )?as (NP_\\\\w+ ? (, )?(and |or )?)+)',\n",
    "#                     'first'\n",
    "#                 ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?like other NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?one of the NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?one of these NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?one of those NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?be example of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which be call NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which be name NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? a kind of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? kind of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? form of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which look like NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?which sound like NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )? NP_\\\\w+ type)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '(compare (NP_\\\\w+ ?(, )?)+(and |or )?with NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and |or )?as NP_\\\\w+)',\n",
    "                    'last'\n",
    "                ),\n",
    "                (\n",
    "                    '((NP_\\\\w+ ?(, )?)+(and|or)? sort of NP_\\\\w+)',\n",
    "                    'last'\n",
    "                )\n",
    "            ])\n",
    "\n",
    "        self.__spacy_nlp = spacy.load('en_core_web_sm')\n",
    "            \n",
    "\n",
    "    def chunk(self, rawtext):\n",
    "        doc = self.__spacy_nlp(rawtext)\n",
    "        chunks = []\n",
    "        for sentence in doc.sents:\n",
    "            sentence_text = sentence.lemma_\n",
    "            for chunk in sentence.noun_chunks:\n",
    "                if chunk.lemma_.lower() == \"example\":\n",
    "                    start = chunk.start\n",
    "                    pre_token = sentence[start - 1].lemma_.lower()\n",
    "                    post_token = sentence[start + 1].lemma_.lower()\n",
    "                    if start > 0 and\\\n",
    "                            (pre_token == \"for\" or post_token == \"of\"):\n",
    "                        continue\n",
    "                if chunk.lemma_.lower() == \"type\":\n",
    "                    continue\n",
    "                chunk_arr = []\n",
    "                replace_arr = []\n",
    "                # print(\"chunk:\", chunk)\n",
    "                for token in chunk:\n",
    "                    if token.lemma_ in self.__adj_stopwords + [\"i.e.\", \"e.g.\"]:\n",
    "                        continue\n",
    "                    chunk_arr.append(token.lemma_)\n",
    "                    # Remove punctuation and stopword adjectives\n",
    "                    # (generally quantifiers of plurals)\n",
    "                    if token.lemma_.isalnum():\n",
    "                        replace_arr.append(token.lemma_)\n",
    "                    else:\n",
    "                        replace_arr.append(''.join(\n",
    "                            char for char in token.lemma_ if char.isalnum()\n",
    "                        ))\n",
    "                if len(chunk_arr) == 0:\n",
    "                    chunk_arr.append(chunk[-1].lemma_)\n",
    "                chunk_lemma = ' '.join(chunk_arr)\n",
    "                # print(chunk_lemma)\n",
    "                replacement_value = 'NP_' + '_'.join(replace_arr)\n",
    "                if chunk_lemma:\n",
    "                    sentence_text = re.sub(r'\\b%s\\b' % re.escape(chunk_lemma),\n",
    "                                           r'%s' % replacement_value,\n",
    "                                           sentence_text)\n",
    "            chunks.append(sentence_text)\n",
    "        return chunks\n",
    "\n",
    "    \"\"\"\n",
    "        This is the main entry point for this code.\n",
    "        It takes as input the rawtext to process and returns a list\n",
    "        of tuples (specific-term, general-term)\n",
    "        where each tuple represents a hypernym pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    def find_hyponyms(self, rawtext):\n",
    "\n",
    "        hyponyms = []\n",
    "        np_tagged_sentences = self.chunk(rawtext)\n",
    "\n",
    "        for sentence in np_tagged_sentences:\n",
    "            # two or more NPs next to each other should be merged\n",
    "            # into a single NP, it's a chunk error\n",
    "            \n",
    "            #hyponyms.append(sentence)\n",
    "\n",
    "            for (hearst_pattern, parser) in self.__hearst_patterns:\n",
    "                matches = re.search(hearst_pattern, sentence)\n",
    "                if matches:\n",
    "                    match_str = matches.group(0)\n",
    "\n",
    "                    nps = [a for a in match_str.split() if a.startswith(\"NP_\")]\n",
    "\n",
    "                    if parser == \"first\":\n",
    "                        general = nps[0]\n",
    "                        specifics = nps[1:]\n",
    "                    else:\n",
    "                        general = nps[-1]\n",
    "                        specifics = nps[:-1]\n",
    "\n",
    "                    for i in range(len(specifics)):\n",
    "                        pair = (\n",
    "                            self.clean_hyponym_term(specifics[i]),\n",
    "                            self.clean_hyponym_term(general)\n",
    "                        )\n",
    "                        # reduce duplicates\n",
    "                        if pair not in hyponyms:\n",
    "                            hyponyms.append(pair)\n",
    "\n",
    "        return hyponyms\n",
    "\n",
    "    def clean_hyponym_term(self, term):\n",
    "        # good point to do the stemming or lemmatization\n",
    "        return term.replace(\"NP_\", \"\").replace(\"_\", \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h = HearstPatterns(extended=True, merge = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[('an exceptional man', 'passenger'), ('al Qaeda', 'loosely affiliate terrorist organization'), ('woman', 'civilian'), ('child', 'civilian'), ('the Egyptian Islamic Jihad', 'country'), ('the Islamic Movement', 'country'), ('Afghanistan', 'place'), ('american citizen', 'all foreign national'), ('Egypt', 'muslim country'), ('Saudi Arabia', 'muslim country'), ('Jordan', 'muslim country'), ('the will', 'every value'), ('the United States', 'a hostile regime'), ('terrorism', 'a threat')]\n"
     ]
    }
   ],
   "source": [
    "hyponyms = h.find_hyponyms(orators[\"bush\"][4])\n",
    "print(len(hyponyms))\n",
    "print(hyponyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(orators[\"bush\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "h = HearstPatterns(extended=True, merge = False)\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "file = \"last_docs.json\"\n",
    "\n",
    "with open(os.path.join(dirpath, file), \"r\") as f:\n",
    "    last_docs = json.load(f)\n",
    "\n",
    "for doc in last_docs:\n",
    "    hyponyms = h.find_hyponyms(doc[1])\n",
    "    #if len(hyponyms[1:]) != 3:\n",
    "    print(doc[1])\n",
    "    print(doc[0], '=>', hyponyms)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-44221e85d621>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-44221e85d621>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    textdata = \"Mr. Speaker, Mr. President Pro Tempore, members of Congress, and fellow Americans:\\nIn the normal course of events, Presidents come to this chamber to report on the state of the Union. Tonight, no such report is needed. It has already been delivered by the American people.\\nWe have seen it in the courage of passengers, who rushed terrorists to save others on the ground -- passengers like an exceptional man named Todd Beamer. And would you please help me to welcome his wife, Lisa Beamer, here tonight. We have seen the state of our Union in the endurance of rescuers, working past exhaustion. We\\'ve seen the unfurling of flags, the lighting of candles, the giving of blood, the saying of prayers -- in English, Hebrew, and Arabic. We have seen the decency of a loving and giving people who have made the grief of strangers their own. My fellow citizens, for the last nine days, the entire world has seen for itself the state of our Union -- and it is strong.\\nTonight we are a country awakened to danger and called to defend freedom. Our grief has turned to anger, and anger to resolution. Whether we bring our enemies to justice, or bring justice to our enemies, justice will be done. I thank the Congress for its leadership at such an important time. All of America was touched on the evening of the tragedy to see Republicans and Democrats joined together on the steps of this Capitol, singing \"God Bless America.\" And you did more than sing; you acted, by delivering 40 billion dollars to rebuild our communities and meet the needs of our military. Speaker Hastert, Minority Leader Gephardt, Majority Leader Daschle, and Senator Lott, I thank you for your friendship, for your leadership, and for your service to our country. And on behalf of the American people, I thank the world for its outpouring of support. America will never forget the sounds of our National Anthem playing at Buckingham Palace, on the streets of Paris, and at Berlin\\'s Brandenburg Gate.\\nWe will not forget South Korean children gathering to pray outside our embassy in Seoul, or the prayers of sympathy offered at a mosque in Cairo. We will not forget moments of silence and days of mourning in Australia and Africa and Latin America. Nor will we forget the citizens of 80 other nations who died with our own: dozens of Pakistanis; more than 130 Israelis; more than 250 citizens of India; men and women from El Salvador, Iran, Mexico, and Japan; and hundreds of British citizens. America has no truer friend than Great Britain. Once again, we are joined together in a great cause -- so honored the British Prime Minister has crossed an ocean to show his unity with America. Thank you for coming, friend.\\nOn September the 11th, enemies of freedom committed an act of war against our country. Americans have known wars -- but for the past 136 years, they have been wars on foreign soil, except for one Sunday in 1941. Americans have known the casualties of war -- but not at the center of a great city on a peaceful morning. Americans have known surprise attacks -- but never before on thousands of civilians. All of this was brought upon us in a single day -- and night fell on a different world, a world where freedom itself is under attack. Americans have many questions tonight. Americans are asking: Who attacked our country? The evidence we have gathered all points to a collection of loosely affiliated terrorist organizations known as al Qaeda. They are some of the murderers indicted for bombing American embassies in Tanzania and Kenya, and responsible for bombing the USS Cole. Al Qaeda is to terror what the mafia is to crime. But its goal is not making money; its goal is remaking the world -- and imposing its radical beliefs on people everywhere.\\nThe terrorists practice a fringe form of Islamic extremism that has been rejected by Muslim scholars and the vast majority of Muslim clerics, a fringe movement that perverts the peaceful teachings of Islam. The terrorists\\' directive commands them to kill Christians and Jews, to kill all Americans, and make no distinctions among military and civilians, including women and children. This group and its leader -- a person named Usama bin Laden -- are linked to many other organizations in different countries, including the Egyptian Islamic Jihad and the Islamic Movement of Uzbekistan. There are thousands of these terrorists in more than 60 countries. They are recruited from their own nations and neighborhoods and brought to camps in places like Afghanistan, where they are trained in the tactics of terror. They are sent back to their homes or sent to hide in countries around the world to plot evil and destruction.\\nThe leadership of al Qaeda has great influence in Afghanistan and supports the Taliban regime in controlling most of that country. In Afghanistan, we see al Qaeda\\'s vision for the world. Afghanistan\\'s people have been brutalized; many are starving and many have fled. Women are not allowed to attend school. You can be jailed for owning a television. Religion can be practiced only as their leaders dictate. A man can be jailed in Afghanistan if his beard is not long enough. \\nThe United States respects the people of Afghanistan. After all, we are currently its largest source of humanitarian aid; but we condemn the Taliban regime. It is not only repressing its own people, it is threatening people everywhere by sponsoring and sheltering and supplying terrorists. By aiding and abetting murder, the Taliban regime is committing murder.\\nAnd tonight, the United States of America makes the following demands on the Taliban: Deliver to United States authorities all the leaders of al Qaeda who hide in your land. Release all foreign nationals, including American citizens, you have unjustly imprisoned. Protect foreign journalists, diplomats, and aid workers in your country. Close immediately and permanently every terrorist training camp in Afghanistan, and hand over every terrorist, and every person in their support structure, to appropriate authorities. Give the United States full access to terrorist training camps, so we can make sure they are no longer operating. These demands are not open to negotiation or discussion. The Taliban must act, and act immediately. They will hand over the terrorists, or they will share in their fate.\\nI also want to speak tonight directly to Muslims throughout the world. We respect your faith. It\\'s practiced freely by many millions of Americans, and by millions more in countries that America counts as friends. Its teachings are good and peaceful, and those who commit evil in the name of Allah blaspheme the name of Allah. The terrorists are traitors to their own faith, trying, in effect, to hijack Islam itself. The enemy of America is not our many Muslim friends; it is not our many Arab friends. Our enemy is a radical network of terrorists, and every government that supports them. Our war on terror begins with al Qaeda, but it does not end there. It will not end until every terrorist group of global reach has been found, stopped, and defeated.\\nAmericans are asking, why do they hate us? They hate what they see right here in this chamber -- a democratically elected government. Their leaders are self-appointed. They hate our freedoms -- our freedom of religion, our freedom of speech, our freedom to vote and assemble and disagree with each other. They want to overthrow existing governments in many Muslim countries, such as Egypt, Saudi Arabia, and Jordan. They want to drive Israel out of the Middle East. They want to drive Christians and Jews out of vast regions of Asia and Africa. These terrorists kill not merely to end lives, but to disrupt and end a way of life. With every atrocity, they hope that America grows fearful, retreating from the world and forsaking our friends. They stand against us, because we stand in their way.\\nWe are not deceived by their pretenses to piety. We have seen their kind before. They are the heirs of all the murderous ideologies of the 20th century. By sacrificing human life to serve their radical visions -- by abandoning every value except the will to power -- they follow in the path of fascism, Nazism, and totalitarianism. And they will follow that path all the way, to where it ends: in history\\'s unmarked grave of discarded lies. Americans are asking: How will we fight and win this war? We will direct every resource at our command -- every means of diplomacy, every tool of intelligence, every instrument of law enforcement, every financial influence, and every necessary weapon of war -- to the disruption and to the defeat of the global terror network.\\nNow this war will not be like the war against Iraq a decade ago, with a decisive liberation of territory and a swift conclusion. It will not look like the air war above Kosovo two years ago, where no ground troops were used and not a single American was lost in combat. Our response involves far more than instant retaliation and isolated strikes. Americans should not expect one battle, but a lengthy campaign, unlike any other we have ever seen. It may include dramatic strikes, visible on TV, and covert operations, secret even in success. We will starve terrorists of funding, turn them one against another, drive them from place to place, until there is no refuge or no rest. And we will pursue nations that provide aid or safe haven to terrorism. Every nation, in every region, now has a decision to make. Either you are with us, or you are with the terrorists. From this day forward, any nation that continues to harbor or support terrorism will be regarded by the United States as a hostile regime.\\nOur nation has been put on notice: We\\'re not immune from attack. We will take defensive measures against terrorism to protect Americans. Today, dozens of federal departments and agencies, as well as state and local governments, have responsibilities affecting homeland security. These efforts must be coordinated at the highest level. So tonight, I announce the creation of a Cabinet-level position reporting directly to me -- the Office of Homeland Security. And tonight I also announce a distinguished American to lead this effort, to strengthen American security: a military veteran, an effective governor, a true patriot, a trusted friend -- Pennsylvania\\'s Tom Ridge. He will lead, oversee, and coordinate a comprehensive national strategy to safeguard our country against terrorism, and respond to any attacks that may come.\\nThese measures are essential. But the only way to defeat terrorism as a threat to our way of life is to stop it, eliminate it, and destroy it where it grows. Many will be involved in this effort, from FBI agents to intelligence operatives to the reservists we have called to active duty. All deserve our thanks, and all have our prayers. And tonight, a few miles from the damaged Pentagon, I have a message for our military: Be ready. I\\'ve called the Armed Forces to alert, and there is a reason. The hour is coming when America will act, and you will make us proud. This is not, however, just America\\'s fight. And what is at stake is not just America\\'s freedom. This is the world\\'s fight. This is civilization\\'s fight. This is the fight of all who believe in progress and pluralism, tolerance and freedom.\\nWe ask every nation to join us. We will ask, and we will need, the help of police forces, intelligence services, and banking systems around the world. The United States is grateful that many nations and many international organizations have already responded -- with sympathy and with support. Nations from Latin America, to Asia, to Africa, to Europe, to the Islamic world. Perhaps the NATO Charter reflects best the attitude of the world: An attack on one is an attack on all. The civilized world is rallying to America\\'s side. They understand that if this terror goes unpunished, their own cities, their own citizens may be next. Terror, unanswered, can not only bring down buildings, it can threaten the stability of legitimate governments. And you know what? We\\'re not going to allow it.\\nAmericans are asking: What is expected of us? I ask you to live your lives, and hug your children. I know many citizens have fears tonight, and I ask you to be calm and resolute, even in the face of a continuing threat. I ask you to uphold the values of America, and remember why so many have come here. We are in a fight for our principles, and our first responsibility is to live by them. No one should be singled out for unfair treatment or unkind words because of their ethnic background or religious faith. I ask you to continue to support the victims of this tragedy with your contributions. Those who want to give can go to a central source of information, libertyunites.org, to find the names of groups providing direct help in New York, Pennsylvania, and Virginia.\\nThe thousands of FBI agents who are now at work in this investigation may need your cooperation, and I ask you to give it. I ask for your patience, with the delays and inconveniences that may accompany tighter security; and for your patience in what will be a long struggle. I ask your continued participation and confidence in the American economy. Terrorists attacked a symbol of American prosperity. They did not touch its source. America is successful because of the hard work, and creativity, and enterprise of our people. These were the true strengths of our economy before September 11th, and they are our strengths today. And, finally, please continue praying for the victims of terror and their families, for those in uniform, and for our great country. Prayer has comforted us in sorrow, and will help strengthen us for the journey ahead.\\nTonight I thank my fellow Americans for what you have already done and for what you will do. And ladies and gentlemen of the Congress, I thank you, their representatives, for what you have already done and for what we will do together. Tonight, we face new and sudden national challenges. We will come together to improve air safety, to dramatically expand the number of air marshals on domestic flights, and take new measures to prevent hijacking. We will come together to promote stability and keep our airlines flying, with direct assistance during this emergency. We will come together to give law enforcement the additional tools it needs to track down terror here at home. We will come together to strengthen our intelligence capabilities to know the plans of terrorists before they act, and to find them before they strike.\\nWe will come together to take active steps that strengthen America\\'s economy, and put our people back to work. Tonight we welcome two leaders who embody the extraordinary spirit of all New Yorkers: Governor George Pataki, and Mayor Rudolph Giuliani. As a symbol of America\\'s resolve, my administration will work with Congress, and these two leaders, to show the world that we will rebuild New York City.\\nAfter all that has just passed -- all the lives taken, and all the possibilities and hopes that died with them -- it is natural to wonder if America\\'s future is one of fear.  Some speak of an age of terror. I know there are struggles ahead, and dangers to face. But this country will define our times, not be defined by them. As long as the United States of America is determined and strong, this will not be an age of terror; this will be an age of liberty, here and across the world.\\nGreat harm has been done to us. We have suffered great loss. And in our grief and anger we have found our mission and our moment. Freedom and fear are at war.  The advance of human freedom -- the great achievement of our time, and the great hope of every time -- now depends on us. Our nation, this generation will lift a dark threat of violence from our people and our future. We will rally the world to this cause by our efforts, by our courage. We will not tire, we will not falter, and we will not fail.\\nIt is my hope that in the months and years ahead, life will return almost to normal.  We\\'ll go back to our lives and routines, and that is good.  Even grief recedes with time and grace. But our resolve must not pass. Each of us will remember what happened that day, and to whom it happened. We\\'ll remember the moment the news came -- where we were and what we were doing. Some will remember an image of a fire, or a story of rescue. Some will carry memories of a face and a voice gone forever.\\nAnd I will carry this: It is the police shield of a man named George Howard, who died at the World Trade Center trying to save others. It was given to me by his mom, Arlene, as a proud memorial to her son. It is my reminder of lives that ended, and a task that does not end. I will not forget this wound to our country or those who inflicted it. I will not yield; I will not rest; I will not relent in waging this struggle for freedom and security for the American people. The course of this conflict is not known, yet its outcome is certain. Freedom and fear, justice and cruelty, have always been at war, and we know that God is not neutral between them.\\nFellow citizens, we\\'ll meet violence with patient justice -- assured of the rightness of our cause, and confident of the victories to come. In all that lies before us, may God grant us wisdom, and may He watch over the United States of America.\\nThank you.\"\u001b[0m\n\u001b[1;37m                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The younger ones occupied themselves as before, some playing cards (there was plenty of money, though there was no food), some with more innocent games, such as quoits and skittles\n",
      "True\n",
      "such_as => [('quoit', 'innocent game'), ('skittle', 'innocent game')]\n",
      "----------\n",
      "The trench itself was the room, in which the lucky ones, such as the squadron commander, had a board, lying on piles at the end opposite the entrance, to serve as a table.\n",
      "True\n",
      "such_as => [('the squadron commander', 'the lucky one')]\n",
      "----------\n",
      "Through the hard century-old bark, even where there were no twigs, leaves had sprouted such as one could hardly believe the old veteran could have produced.\n",
      "False\n",
      "such_as => []\n",
      "----------\n",
      "Religion alone can explain to us what without its help man cannot comprehend: why, for what cause, kind and noble beings able to find happiness in life—not merely harming no one but necessary to the happiness of others—are called away to God, while cruel, useless, harmful persons, or such as are a burden to themselves and to others, are left living\n",
      "False\n",
      "such_as => []\n",
      "----------\n",
      "The youthful little Princess Bolkónskaya, known as la femme la plus séduisante de Pétersbourg\n",
      "True\n",
      "known_as => []\n",
      "----------\n",
      "The prince’s house did not belong to what is known as fashionable society, but his little circle—though not much talked about in town—was one it was more flattering to be received in than any other.\n",
      "False\n",
      "known_as => []\n",
      "----------\n",
      "And Prince Hippolyte began to tell his story in such Russian as a Frenchman would speak after spending about a year in Russia.\n",
      "False\n",
      "such_NOUN_as => [('a Frenchman', 'Russian'), ('Russian', 'a Frenchman')]\n",
      "----------\n",
      "at such a moment as this one must think of everything\n",
      "False\n",
      "such_NOUN_as => [('this one', 'a moment'), ('a moment', 'this one')]\n",
      "----------\n",
      "Come, I will go with you. Try to weep, nothing gives such relief as tears.\n",
      "True\n",
      "such_NOUN_as => [('tear', 'relief'), ('relief', 'tear')]\n",
      "----------\n",
      "It uplifts the soul to see such men as the old count and his worthy son\n",
      "True\n",
      "such_NOUN_as => []\n",
      "----------\n",
      "others simply enjoyed hearing how the master talked, while the cleverest among them, including the chief steward, understood from this speech how they could best handle the master for their own ends\n",
      "True\n",
      "include => []\n",
      "----------\n",
      "On the twenty-ninth of May Napoleon left Dresden, where he had spent three weeks surrounded by a court that included princes, dukes, kings, and even an emperor\n",
      "True\n",
      "include => []\n",
      "----------\n",
      "Pierre respected this class of Brothers to which the elder ones chiefly belonged, including, Pierre thought, Joseph Alexéevich himself, but he did not share their interests.\n",
      "False\n",
      "include => []\n",
      "----------\n",
      "About twenty people were present, including Dólokhov and Denísov\n",
      "False\n",
      "include => []\n",
      "----------\n",
      "They are regular brigands, especially Dólokhov\n",
      "True\n",
      "especially => [('Dólokhov', 'regular brigand')]\n",
      "----------\n",
      "But he did not run after the unmarried girls, especially the rich heiresses who were most of them plain.\n",
      "True\n",
      "especially => [('the rich heiress', 'the unmarried girl'), ('who', 'the unmarried girl')]\n",
      "----------\n",
      "The faces of these young people, especially those who were military men, bore that expression of condescending respect for their elders which seems to say to the older generation, “We are prepared to respect and honor you, but all the same remember that the future belongs to us.\n",
      "True\n",
      "especially => []\n",
      "----------\n",
      "Her pretty little upper lip, on which a delicate dark down was just perceptible, was too short for her teeth, but it lifted all the more sweetly, and was especially charming when she occasionally drew it down to meet the lower lip\n",
      "False\n",
      "especially => []\n",
      "----------\n",
      "The story was very pretty and interesting, especially at the point where the rivals suddenly recognized one another; and the ladies looked agitated.\n",
      "False\n",
      "especially => []\n",
      "----------\n",
      "and the vicomte was served up to the company in the choicest and most advantageous style, like a well-garnished joint of roast beef on a hot dish.\n",
      "True\n",
      "like => []\n",
      "----------\n",
      "It is only necessary for one powerful nation like Russia — barbaric as she is said to be — to place herself disinterestedly at the head of an alliance having for its object the maintenance of the balance of power of Europe, and it would save the world!\n",
      "True\n",
      "like => [('Russia', 'one powerful nation')]\n",
      "----------\n",
      "It was evident that he did not like the vicomte and was aiming his remarks at him, though without looking at him.\n",
      "False\n",
      "like => []\n",
      "----------\n",
      "You treat me like an invalid or a child. I see it all! Did you behave like that six months ago?\n",
      "False\n",
      "like => []\n",
      "----------\n",
      "Natásha, that winter, had for the first time begun to sing seriously, mainly because Denísov so delighted in her singing.\n",
      "False\n",
      "mainly => []\n",
      "----------\n",
      "Moreover, he could see by her manners that she was one of those women—mostly mothers—who, having once made up their minds, will not rest until they have gained their end, and are prepared if necessary to go on insisting day after day and hour after hour, and even to make scenes.\n",
      "True\n",
      "mostly => []\n",
      "----------\n",
      "All the members of the lodges were men Pierre knew in ordinary life, and it was difficult for him to regard them merely as Brothers in Freemasonry and not as Prince B. or Iván Vasílevich D., whom he knew in society mostly as weak and insignificant men\n",
      "False\n",
      "mostly => []\n",
      "----------\n",
      "\n",
      "None\n",
      "notably => []\n",
      "----------\n",
      "L'amour which the Frenchman worshiped consisted principally in the unnaturalness of his relation to the woman and in a combination of incongruities giving the chief charm to the feeling.\n",
      "False\n",
      "principally => []\n",
      "----------\n",
      "While waiting for the announcement of his appointment to the committee Prince Andrew looked up his former acquaintances, particularly those he knew to be in power and whose aid he might need.\n",
      "False\n",
      "particularly => []\n",
      "----------\n",
      "Rostóv was particularly in need of money now that the troops, after their active service, were stationed near Olmütz and the camp swarmed with well-provisioned sutlers and Austrian Jews offering all sorts of tempting wares.\n",
      "False\n",
      "particularly => []\n",
      "----------\n",
      "The three great sorrows of his life held his attention in particular: his love for a woman, his father’s death, and the French invasion which had overrun half Russia.\n",
      "True\n",
      "in_particular => []\n",
      "----------\n",
      "And as he waved his arms to impersonate the policeman, his portly form again shook with a deep ringing laugh, the laugh of one who always eats well and, in particular, drinks well.\n",
      "False\n",
      "in_particular => []\n",
      "----------\n",
      "She was not in love with anyone in particular, but with everyone\n",
      "False\n",
      "in_particular => []\n",
      "----------\n",
      "There was now no one in the reception room except Prince Vasíli and the eldest princess, who were sitting under the portrait of Catherine the Great and talking eagerly\n",
      "True\n",
      "except => [('Prince Vasíli', 'the reception room'), ('the eld princess', 'the reception room'), ('who', 'the reception room')]\n",
      "----------\n",
      "He made use of every kind of mental device, except analogy, and passed too boldly, it seemed to Prince Andrew, from one to another.\n",
      "True\n",
      "except => [('analogy', 'mental device')]\n",
      "----------\n",
      "There was really nothing to be seen in front except a barren descent hidden by dense mist.\n",
      "False\n",
      "except => [('a barren descent', 'front')]\n",
      "----------\n",
      "Kutúzov no one spoke of, except some who abused him in whispers, calling him a court weathercock and an old satyr.\n",
      "False\n",
      "except => []\n",
      "----------\n",
      "\n",
      "None\n",
      "other_than => []\n",
      "----------\n",
      "In front was Glory, which was similar to those threads but rather thicker.\n",
      "True\n",
      "which_be_similar_to => []\n",
      "----------\n",
      "\n",
      "None\n",
      "example_of_this_be => []\n",
      "----------\n",
      "Countess Bezúkhova was present among other Russian ladies who had followed the sovereign from Petersburg to Vílna and eclipsed the refined Polish ladies by her massive, so-called Russian type of beauty\n",
      "False\n",
      "type => []\n",
      "----------\n",
      "When we do not at all understand the cause of an action, whether a crime, a good action, or even one that is simply nonmoral, we ascribe a greater amount of freedom to it.\n",
      "True\n",
      "whether => []\n",
      "----------\n",
      "She could not fathom whether it was curiosity, devotion, gratitude, or apprehension and distrust—but the expression on all the faces was identical.\n",
      "False\n",
      "whether => []\n",
      "----------\n",
      "He opened his eyes, hoping to see how the struggle of the Frenchmen with the gunners ended, whether the red-haired gunner had been killed or not and whether the cannon had been captured or saved.\n",
      "False\n",
      "weather => []\n",
      "----------\n",
      "\n",
      "None\n",
      "compare_to => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which may include => []\n",
      "----------\n",
      "\n",
      "None\n",
      "for_instance => []\n",
      "----------\n",
      "But the most amazing example of the ineffectiveness of the orders given by the authorities at that time was Napoleon’s attempt to stop the looting and re-establish discipline.\n",
      "False\n",
      "example_of => []\n",
      "----------\n",
      "and so, led astray by pride, losing sight of this aim, we occupy ourselves either with the mystery which in our impurity we are unworthy to receive, or seek the reformation of the human race while ourselves setting an example of baseness and profligacy\n",
      "False\n",
      "example_of => []\n",
      "----------\n",
      "To the defenders of the laws of Copernicus and Newton, to Voltaire for example, it seemed that the laws of astronomy destroyed religion, and he utilized the law of gravitation as a weapon against religion.\n",
      "False\n",
      "for_example => [('gravitation', 'a weapon')]\n",
      "----------\n",
      "Several persons, among them the elderly lady and Anna Pávlovna, did however smile.\n",
      "True\n",
      "among_-PRON- => []\n",
      "----------\n",
      "As the bearers, among whom was Anna Mikháylovna, passed the young man he caught a momentary glimpse between their heads and backs of the dying man’s high, stout, uncovered chest and powerful shoulders, raised by those who were holding him under the armpits, and of his gray, curly, leonine head.\n",
      "True\n",
      "among_-PRON- => []\n",
      "----------\n",
      "I am fond of you, especially as you are the one live man among our whole set\n",
      "False\n",
      "among_-PRON- => []\n",
      "----------\n",
      "This young man, of whom I spoke to you last summer, is so noble-minded and full of that real youthfulness which one seldom finds nowadays among our old men of twenty and, particularly, he is so frank and has so much heart.\n",
      "False\n",
      "among_-PRON- => []\n",
      "----------\n",
      "\n",
      "None\n",
      "e.g. => []\n",
      "----------\n",
      "\n",
      "None\n",
      "i.e.. => []\n",
      "----------\n",
      "Pierre went home, but Rostóv with Dólokhov and Denísov stayed on at the club till late, listening to the gypsies and other singers\n",
      "True\n",
      "other => [('the gypsy', 'singer')]\n",
      "----------\n",
      "That night the doors were again broken open, the padlocks smashed, the books mutilated, and other disorders perpetrated.\n",
      "True\n",
      "other => []\n",
      "----------\n",
      "It is only to prevent some Pugachëv or other from killing my children and yours, and Arakchéev from sending me off to some Military Settlement.\n",
      "False\n",
      "other => []\n",
      "----------\n",
      "At that instant the sun began to hide behind the clouds, and other stretchers came into view before Rostóv.\n",
      "False\n",
      "other => [('the cloud', 'stretcher')]\n",
      "----------\n",
      "Tíkhon knew that neither the son’s arrival nor any other unusual event must be allowed to disturb the appointed order of the day.\n",
      "False\n",
      "any_other => []\n",
      "----------\n",
      "Amid the general rumble, the groans and voices of the wounded were more distinctly heard than any other sound in the darkness of the night.\n",
      "False\n",
      "any_other => []\n",
      "----------\n",
      "There was about him something of Weyrother, Mack, and Schmidt, and many other German theorist-generals whom Prince Andrew had seen in 1805, but he was more typical than any of them.\n",
      "True\n",
      "many_other => []\n",
      "----------\n",
      "there were up to that time very few, but she mentioned Napoleon and some other exalted personages\n",
      "True\n",
      "some_other => []\n",
      "----------\n",
      "Each historian, according to his view of what constitutes a nation’s progress, looks for these conditions in the greatness, wealth, freedom, or enlightenment of citizens of France or some other country.\n",
      "True\n",
      "some_other => []\n",
      "----------\n",
      "While Russia was well, a foreigner could serve her and be a splendid minister\n",
      "False\n",
      "be_a => []\n",
      "----------\n",
      "All the well-known people of that period, from Alexander and Napoleon to Madame de Staël, Photius, Schelling, Fichte, Chateaubriand, and the rest, pass before their stern judgment seat and are acquitted or condemned according to whether they conduced to progress or to reaction.\n",
      "False\n",
      "be_a => []\n",
      "----------\n",
      "\n",
      "None\n",
      "like_other => []\n",
      "----------\n",
      "On his return to Moscow from the army, Nicholas Rostóv was welcomed by his home circle as the best of sons, a hero, and their darling Nikólenka; by his relations as a charming, attractive, and polite young man; by his acquaintances as a handsome lieutenant of hussars, a good dancer, and one of the best matches in the city.\n",
      "True\n",
      "one_of_the => []\n",
      "----------\n",
      "A door of one of the inner rooms opened and one of the princesses, the count’s niece, entered with a cold, stern face.\n",
      "False\n",
      "one_of_the => []\n",
      "----------\n",
      "Of the two soups he chose turtle with savory patties and went on to the game without omitting a single dish or one of the wines.\n",
      "False\n",
      "one_of_the => []\n",
      "----------\n",
      "She loved and knew Prince Andrew, he loved her only, and was to come one of these days and take her.\n",
      "True\n",
      "one_of_these => []\n",
      "----------\n",
      "Prince Andrew was one of those rare staff officers whose chief interest lay in the general progress of the war.\n",
      "True\n",
      "one_of_those => [('whose chief interest', 'rare staff officer')]\n",
      "----------\n",
      "\n",
      "None\n",
      "be_example_of => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_be_call => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_be_name => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_look_lile => []\n",
      "----------\n",
      "\n",
      "None\n",
      "which_sound_like => []\n",
      "----------\n",
      "Casting a rapid glance at all those in the room and noticing the count’s confessor there, she glided up to him with a sort of amble, not exactly bowing yet seeming to grow suddenly smaller, and respectfully received the blessing first of one and then of another priest.\n",
      "False\n",
      "sort_of => []\n",
      "----------\n",
      "He felt it awkward to attract everyone’s attention and to be considered a lucky man and, with his plain face, to be looked on as a sort of Paris possessed of a Helen.\n",
      "False\n",
      "sort_of => []\n",
      "----------\n",
      "/'Yes, I feel a kind of oppression,/' she said in reply to the prince’s question as to how she felt.\n",
      "False\n",
      "a_kind_of => []\n",
      "----------\n",
      "Yet in this very repugnance to all his circumstances Pierre found a kind of tantalizing satisfaction.\n",
      "False\n",
      "a_kind_of => []\n",
      "----------\n",
      "Life was cheaper because it was circumscribed: that most expensive luxury, the kind of life that can be changed at any moment, was no longer his nor did he wish for it.\n",
      "False\n",
      "kind_of => []\n",
      "----------\n",
      "Secondly, it is assumed that the goal toward which humanity is being led is known to the historians: to one of them this goal is the greatness of the Roman, Spanish, or French realm; to another it is liberty, equality, and a certain kind of civilization of a small corner of the world called Europe.\n",
      "False\n",
      "kind_of => []\n",
      "----------\n",
      "\n",
      "None\n",
      "form_of => []\n",
      "----------\n",
      "\n",
      "None\n",
      "as => []\n",
      "----------\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "h = HearstPatterns(extended=True, merge = False)\n",
    "\n",
    "dirpath = r\"C:\\Users\\Steve\\OneDrive - University of Southampton\\CNDPipeline\\dataset\\Tolstoy\"\n",
    "file = \"warandpeace_testdata.json\"\n",
    "\n",
    "with open(os.path.join(dirpath, file), \"r\") as f:\n",
    "    docs = json.load(f)\n",
    "    \n",
    "for doc in docs:\n",
    "    hyponyms = h.find_hyponyms(doc[2])\n",
    "    #if len(hyponyms[1:]) != 3:\n",
    "    print(doc[2])\n",
    "    print(doc[1])\n",
    "    print(doc[0], '=>', hyponyms)\n",
    "    print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E\n",
      "======================================================================\n",
      "ERROR: test_hyponym_finder (__main__.TestHearstPatterns)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-14-71766177d2a3>\", line 47, in test_hyponym_finder\n",
      "    self.assertEqual(tuple(map(str.lower, hyps7[0])), (\"apple\", \"fruit\"))\n",
      "IndexError: list index out of range\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.191s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestHearstPatterns(unittest.TestCase):\n",
    "\n",
    "    def test_hyponym_finder(self):\n",
    "        h = HearstPatterns(extended=True)\n",
    "\n",
    "        # H1\n",
    "        hyps1 = h.find_hyponyms(\"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\")\n",
    "\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[0])), (\"red eye\", \"symptom\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[1])), (\"ocular pain\", \"symptom\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[2])), (\"visual acuity\", \"symptom\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps1[3])), (\"photophobia\", \"symptom\"))\n",
    "\n",
    "        # H2\n",
    "        hyps2 = h.find_hyponyms(\"There are works by such authors as Herrick, Goldsmith, and Shakespeare.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps2[0])), (\"herrick\", \"author\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps2[1])), (\"goldsmith\", \"author\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps2[2])), (\"shakespeare\", \"author\"))\n",
    "\n",
    "        # H3\n",
    "        hyps3 = h.find_hyponyms(\"There were bruises, lacerations, or other injuries were not prevalent.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps3[0])), (\"bruise\", \"injury\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps3[1])), (\"laceration\", \"injury\"))\n",
    "\n",
    "        # H4\n",
    "        hyps4 = h.find_hyponyms(\"common law countries, including Canada, Australia, and England enjoy toast.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps4[0])), (\"canada\", \"common law country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps4[1])), (\"australia\", \"common law country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps4[2])), (\"england\", \"common law country\"))\n",
    "\n",
    "        # H5\n",
    "        hyps5 = h.find_hyponyms(\"Many countries, especially France, England and Spain also enjoy toast.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps5[0])), (\"france\", \"country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps5[1])), (\"england\", \"country\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps5[2])), (\"spain\", \"country\"))\n",
    "\n",
    "        # H2\n",
    "        hyps6 = h.find_hyponyms(\"There are such benefits as postharvest losses reduction, food increase and soil fertility improvement.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps6[0])), (\"postharvest loss reduction\", \"benefit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps6[1])), (\"food increase\", \"benefit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps6[2])), (\"soil fertility improvement\", \"benefit\"))\n",
    "\n",
    "        # H'1\n",
    "        hyps7 = h.find_hyponyms(\"Fruits, i.e. , apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        hyps7 = h.find_hyponyms(\"Fruits, e.g. apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps7[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        # H'2\n",
    "\n",
    "        hyps10 = h.find_hyponyms(\"Fruits (e.g. apples, bananas, oranges and peaches.)\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        hyps10 = h.find_hyponyms(\"Fruits (i.e. apples, bananas, oranges and peaches.)\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps10[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        # H'3\n",
    "        hyps8 = h.find_hyponyms(\"Fruits, for example apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps8[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "        # H'4\n",
    "        hyps9 = h.find_hyponyms(\"Fruits, which may include apples, bananas, oranges and peaches.\")\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[0])), (\"apple\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[1])), (\"banana\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[2])), (\"orange\", \"fruit\"))\n",
    "        self.assertEqual(tuple(map(str.lower, hyps9[3])), (\"peach\", \"fruit\"))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F\n",
      "======================================================================\n",
      "FAIL: test_hyponym_finder (__main__.TestHearstPatterns)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-5-88c88a93b418>\", line 14, in test_hyponym_finder\n",
      "    self.assertEqual(hyps2[0], (\"herrick\", \"author\"))\n",
      "AssertionError: Tuples differ: ('Herrick', 'author') != ('herrick', 'author')\n",
      "\n",
      "First differing element 0:\n",
      "'Herrick'\n",
      "'herrick'\n",
      "\n",
      "- ('Herrick', 'author')\n",
      "?   ^\n",
      "\n",
      "+ ('herrick', 'author')\n",
      "?   ^\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.183s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestHearstPatterns(unittest.TestCase):\n",
    "\n",
    "    def test_hyponym_finder(self):\n",
    "        h = HearstPatterns()\n",
    "        hyps1 =  h.find_hyponyms(\"Forty-four percent of patients with uveitis had one or more identifiable signs or symptoms, such as red eye, ocular pain, visual acuity, or photophobia, in order of decreasing frequency.\")\n",
    "        self.assertEqual(hyps1[0], (\"red eye\", \"symptom\"))\n",
    "        self.assertEqual(hyps1[1], (\"ocular pain\", \"symptom\"))\n",
    "        self.assertEqual(hyps1[2], (\"visual acuity\", \"symptom\"))\n",
    "        self.assertEqual(hyps1[3], (\"photophobia\", \"symptom\"))\n",
    "\n",
    "        hyps2 = h.find_hyponyms(\"There are works by such authors as Herrick, Goldsmith, and Shakespeare.\")\n",
    "        self.assertEqual(hyps2[0], (\"herrick\", \"author\"))\n",
    "        self.assertEqual(hyps2[1], (\"goldsmith\", \"author\"))\n",
    "        self.assertEqual(hyps2[2], (\"shakespeare\", \"author\"))\n",
    "\n",
    "        hyps3 = h.find_hyponyms(\"There were bruises, lacerations, or other injuries were not prevalent.\")\n",
    "        self.assertEqual(hyps3[0], (\"bruise\", \"injury\"))\n",
    "        self.assertEqual(hyps3[1], (\"laceration\", \"injury\"))\n",
    "\n",
    "        hyps4 =  h.find_hyponyms(\"common law countries, including Canada, Australia, and England enjoy toast.\")\n",
    "        self.assertEqual(hyps4[0], (\"canada\", \"common law country\"))\n",
    "        self.assertEqual(hyps4[1], (\"australia\", \"common law country\"))\n",
    "        self.assertEqual(hyps4[2], (\"england\", \"common law country\"))\n",
    "\n",
    "        hyps5 = h.find_hyponyms(\"Many countries, especially France, England and Spain also enjoy toast.\")\n",
    "        self.assertEqual(hyps5[0], (\"france\", \"country\"))\n",
    "        self.assertEqual(hyps5[1], (\"england\", \"country\"))\n",
    "        self.assertEqual(hyps5[2], (\"spain\", \"country\"))\n",
    "\n",
    "        hyps6 = h.find_hyponyms(\"There are such benefits as postharvest losses reduction, food increase and soil fertility improvement.\")\n",
    "        self.assertEqual(hyps6[0], (\"postharvest loss reduction\", \"benefit\"))\n",
    "        self.assertEqual(hyps6[1], (\"food increase\", \"benefit\"))\n",
    "        self.assertEqual(hyps6[2], (\"soil fertility improvement\", \"benefit\"))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
