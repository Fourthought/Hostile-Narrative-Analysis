{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'Named Entity Matcher', 'merge_entities', 'Concept Matcher', 'merge_custom_chunks', 'hearst pattern matcher']\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import importlib\n",
    "import cndlib.pipeline\n",
    "importlib.reload(cndlib.pipeline)\n",
    "\n",
    "cnd = cndlib.pipeline.CND()\n",
    "\n",
    "print([name for name in cnd.nlp.pipe_names])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text Count</th>\n",
       "      <th>Word Count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hitler</th>\n",
       "      <th>0</th>\n",
       "      <td>Adolf Hitler</td>\n",
       "      <td>1</td>\n",
       "      <td>706100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bush</th>\n",
       "      <th>1</th>\n",
       "      <td>George Bush</td>\n",
       "      <td>14</td>\n",
       "      <td>143936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>king</th>\n",
       "      <th>2</th>\n",
       "      <td>Martin Luther King</td>\n",
       "      <td>5</td>\n",
       "      <td>122815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laden</th>\n",
       "      <th>3</th>\n",
       "      <td>Osama bin Laden</td>\n",
       "      <td>6</td>\n",
       "      <td>93664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Totals</th>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>26</td>\n",
       "      <td>1066515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  Text Count  Word Count\n",
       "Ref                                                 \n",
       "hitler 0        Adolf Hitler           1      706100\n",
       "bush   1         George Bush          14      143936\n",
       "king   2  Martin Luther King           5      122815\n",
       "laden  3     Osama bin Laden           6       93664\n",
       "Totals 4                              26     1066515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import importlib\n",
    "from IPython.display import clear_output\n",
    "import cndlib.cndobjects\n",
    "importlib.reload(cndlib.cndobjects)\n",
    "\n",
    "\n",
    "dirpath = r'C:\\\\Users\\\\spa1e17\\\\OneDrive - University of Southampton\\\\hostile-narrative-analysis\\\\dataset'\n",
    "\n",
    "orators = cndlib.cndobjects.Dataset(cnd, dirpath)\n",
    "clear_output(wait=True)\n",
    "\n",
    "display(orators.summarise())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create .csv Files of Sentences of Each Orator for Annotation\n",
    "\n",
    "In this experiment we test sentiment analysis to detect the ingroup elevation and outgroup other phrases. For this experiment, each sentence of Bush and bin Laden’s datasets have been annotated as either ingroup elevation or outgroup othering. Accordingly, annotation was based on two criteria. Firstly, the sentence must contain reference to a named entity, whether explicitly or by either noun phrase or pronoun. Secondly, the reference must be associated with a term in the sentence which either elevates or others the reference entity. For example, with an implicit reference to al Qaeda, the following two sentences from Bush are annotated as othering, “These terrorists don't represent peace”, “They represent evil and war”. Equally, from both datasets the clauses, “God bless America” or “Allah blessed be upon him” are annotated as elevation.\n",
    "\n",
    "An extra annotation was also added for hostile and anti-sematic sentences. Hostile sentences are those containing a threat of violence. For example from bin Laden, “And whoever has killed our civilians, then we have the right to kill theirs”, or from Bush, “We are sending a signal to the world as we speak that if you harbor a terrorist, there will be a price to pay.”. Some hostile sentences are veiled threat, but in the context of the narrative are determined to be threatening. Bin Laden’s explicit outgroup are Jews and Israel, as such, may of his sentences have been annotated as Ant-Sematic. The International Holocaust Remembrance Alliance (IHRC) definition of anti-Semitism was used as a guide for these annotations . An example of one annotation is, “Behind them stand the Jews, who control your policies, media and economy”. In this sentence bin Laden suggests Jewish people control the wealthy Americans, which conforms with the IHRC’s anti-Semitic characterisation of Jewish control of “Jews controlling the media, economy, government or other societal institutions”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Orator</th>\n",
       "      <th>Number of Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>George Bush</td>\n",
       "      <td>1598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Osama bin Laden</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Martin Luther King</td>\n",
       "      <td>1290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adolf Hitler</td>\n",
       "      <td>4487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Orator  Number of Sentences\n",
       "0         George Bush                 1598\n",
       "1     Osama bin Laden                  750\n",
       "2  Martin Luther King                 1290\n",
       "3        Adolf Hitler                 4487"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "docs = {\"bush\" : {\"name\" : \"George Bush\", \"filename\" : \"bush_sentences_gold.txt\", \"sentences\" : []},\n",
    "       \"laden\" : {\"name\" : \"Osama bin Laden\", \"filename\" : \"bush_sentences_gold.txt\", \"sentences\" : []},\n",
    "       \"king\" : {\"name\" : \"Martin Luther King\", \"sentences\" : []},\n",
    "       \"hitler\" : {\"name\" : \"Adolf Hitler\", \"sentences\" : []}}\n",
    "\n",
    "dirpath = os.getcwd()\n",
    "\n",
    "for orator, texts in orators.orators_dict.items():\n",
    "    \n",
    "    \n",
    "    for text in texts.texts:\n",
    "        for sentence in text.doc.sents:\n",
    "            sent = {\"function\" : \"\", \"hostile\" : \"\", \"text\" : sentence.text.replace('\\n', ' ').strip()}\n",
    "            docs[orator]['sentences'].append(sent)\n",
    "    \n",
    "    filename = f\"{orator}_sentences.csv\"\n",
    "    df = pd.DataFrame(docs[orator]['sentences'])\n",
    "    filepath = os.path.join(dirpath, filename)\n",
    "    \n",
    "    df.to_csv(filepath, sep=',',index=False)\n",
    "\n",
    "            \n",
    "pd.DataFrame([{\"Orator\" : doc['name'], \n",
    "               \"Number of Sentences\" : len(doc['sentences'])} \n",
    "              for doc in docs.values()\n",
    "             ])\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Annotation Results for Scoring by Sentiment Analysis APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512\" style='display:inline'><caption>Elevation and Othering Annotation Results</caption><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Number of Sentences</th>        <th class=\"col_heading level0 col1\" >Elevation Sentences</th>        <th class=\"col_heading level0 col2\" >Othering Sentences</th>        <th class=\"col_heading level0 col3\" >Hostile Sentences</th>        <th class=\"col_heading level0 col4\" >Antisemitic Sentences</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512level0_row0\" class=\"row_heading level0 row0\" >George Bush</th>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row0_col0\" class=\"data row0 col0\" >1594</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row0_col1\" class=\"data row0 col1\" >215</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row0_col2\" class=\"data row0 col2\" >119</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row0_col3\" class=\"data row0 col3\" >37</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row0_col4\" class=\"data row0 col4\" ></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512level0_row1\" class=\"row_heading level0 row1\" >Osama bin Laden</th>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row1_col0\" class=\"data row1 col0\" >716</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row1_col1\" class=\"data row1 col1\" >58</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row1_col2\" class=\"data row1 col2\" >147</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row1_col3\" class=\"data row1 col3\" >18</td>\n",
       "                        <td id=\"T_c0549b1c_64cb_11eb_b180_2cdb07cef512row1_col4\" class=\"data row1 col4\" >8</td>\n",
       "            </tr>\n",
       "    </tbody></table>   "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from cndlib.visuals import display_side_by_side\n",
    "\n",
    "docs = {\n",
    "    \"bush\" : {\"name\" : \"George Bush\", \"filename\" : \"bush_sentences_gold.txt\", \"sentences\" : None},\n",
    "    \"laden\" : {\"name\" : \"Osama bin Laden\", \"filename\" : \"laden_sentences_gold.txt\", \"sentences\" : None}\n",
    "}\n",
    "\n",
    "for orator in docs.values():\n",
    "    filename = filename = os.path.join(os.getcwd(), orator['filename'])\n",
    "\n",
    "    with open(filename, newline = \"\") as fp:\n",
    "        data = csv.DictReader(fp, delimiter = '\\t')\n",
    "\n",
    "        orator['sentences'] = [row for row in data]\n",
    "        \n",
    "df = pd.DataFrame()\n",
    "for orator in docs.values():\n",
    "    \n",
    "    summary = []\n",
    "    summary.append({\"Number of Sentences\" : len(orator['sentences'])})\n",
    "    df2 = pd.DataFrame(orator['sentences'])\n",
    "    summary.extend([{f\"{k.title()} Sentences\" : str(v) for k, v in df2['function'].value_counts().items() if k}])\n",
    "    summary.extend([{f\"{k.title()} Sentences\" : str(v) for k, v in df2['hostile'].value_counts().items() if k}])\n",
    "    \n",
    "    df = pd.concat([df, pd.DataFrame({k:v for x in summary for k,v in x.items()}, index = [orator['name']])])\n",
    "    \n",
    "display_side_by_side([df.fillna('')], [\"Elevation and Othering Annotation Results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Google API Results\n",
    "\n",
    "https://cloud.google.com/natural-language/docs/basics#:~:text=score%20of%200.8%20.-,Interpreting%20sentiment%20analysis%20values,the%20length%20of%20the%20document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "George Bush: 100%|██████████| 1594/1594 [00:00<00:00, 785261.99it/s]\n",
      "Osama bin Laden: 100%|██████████| 716/716 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>progress</th>\n",
       "      <th>function</th>\n",
       "      <th>hostile</th>\n",
       "      <th>interesting</th>\n",
       "      <th>text</th>\n",
       "      <th>google sentiment score</th>\n",
       "      <th>google sentiment magnitute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0%</td>\n",
       "      <td>elevation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>It is God that we thank and it is God whose he...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0%</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Whoever is guided by God cannot be misled and ...</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1%</td>\n",
       "      <td>elevation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>I declare that there is no God but Allah and t...</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1%</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\"</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1%</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>O ye who believe, fear God as he should be fea...</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>100%</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>No.</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>100%</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Your security is in your own hands.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>100%</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>And every state that doesn't play with our sec...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>100%</td>\n",
       "      <td>elevation</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>And Allah is our Guardian and Helper, while yo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>100%</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>All peace be upon he who follows the Guidance.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>716 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    progress   function hostile interesting  \\\n",
       "0         0%  elevation                       \n",
       "1         0%                                  \n",
       "2         1%  elevation                       \n",
       "3         1%                                  \n",
       "4         1%                                  \n",
       "..       ...        ...     ...         ...   \n",
       "711     100%                                  \n",
       "712     100%                                  \n",
       "713     100%                                  \n",
       "714     100%  elevation                       \n",
       "715     100%                                  \n",
       "\n",
       "                                                  text  \\\n",
       "0    It is God that we thank and it is God whose he...   \n",
       "1    Whoever is guided by God cannot be misled and ...   \n",
       "2    I declare that there is no God but Allah and t...   \n",
       "3                                                    \"   \n",
       "4    O ye who believe, fear God as he should be fea...   \n",
       "..                                                 ...   \n",
       "711                                                No.   \n",
       "712                Your security is in your own hands.   \n",
       "713  And every state that doesn't play with our sec...   \n",
       "714  And Allah is our Guardian and Helper, while yo...   \n",
       "715     All peace be upon he who follows the Guidance.   \n",
       "\n",
       "     google sentiment score  google sentiment magnitute  \n",
       "0                       0.7                         0.7  \n",
       "1                      -0.8                         0.8  \n",
       "2                      -0.3                         0.3  \n",
       "3                       0.2                         0.2  \n",
       "4                      -0.6                         0.6  \n",
       "..                      ...                         ...  \n",
       "711                    -0.6                         0.6  \n",
       "712                     0.0                         0.0  \n",
       "713                     0.0                         0.0  \n",
       "714                     0.0                         0.0  \n",
       "715                     0.5                         0.5  \n",
       "\n",
       "[716 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "# instantiate Google Sentiment Analysis\n",
    "from google.cloud import language_v1\n",
    "client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    \n",
    "# iterate through each orator() object\n",
    "for orator in docs.values():\n",
    "   \n",
    "    # iterate over each Text() of the orator() object\n",
    "    for sent_obj in tqdm(orator['sentences'], total = len(orator['sentences']), desc = orator['name']):\n",
    "\n",
    "        text = sent_obj['text']\n",
    "#         document = language_v1.Document(content=text, type_=language_v1.Document.Type.PLAIN_TEXT)\n",
    "        \n",
    "#         sentiment = client.analyze_sentiment(request={'document': document}).document_sentiment\n",
    "#         sent_obj['google sentiment score'] = sentiment.score\n",
    "#         sent_obj['google sentiment magnitude'] = sentiment.magnitude\n",
    "\n",
    "display(pd.DataFrame([obj for obj in docs['laden']['sentences']]))\n",
    "    \n",
    "# google_document_results = document_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IBM Watson API Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 997 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, SentimentOptions, EmotionOptions\n",
    "\n",
    "apikey = 'D3ptPkoLkoQNJvIav-reiA5137cr3m8Y1f-mhX1bLile'\n",
    "url = 'https://api.eu-gb.natural-language-understanding.watson.cloud.ibm.com/instances/204e6ba7-952c-41ae-99e9-fe4e8208bfde'\n",
    "\n",
    "authenticator = IAMAuthenticator(apikey)\n",
    "service = NaturalLanguageUnderstandingV1(version='2019-07-12', authenticator=authenticator)\n",
    "service.set_service_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Osama bin Laden: 100%|██████████| 716/716 [06:08<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "for orator in docs.values():\n",
    "    \n",
    "    for sent_obj in tqdm(orator['sentences'], total = len(orator['sentences']), desc = orator['name']):\n",
    "  \n",
    "        text = sent_obj['text']\n",
    "        analytics = service.analyze(text=text, features=Features(\n",
    "                                    sentiment=SentimentOptions(), \n",
    "                                    emotion=EmotionOptions()),\n",
    "                                    language = \"en\").get_result()\n",
    "        \n",
    "        sent_obj['watson sentiment'] = analytics['sentiment']['document']['score']\n",
    "        emotion = analytics['emotion']['document']['emotion']\n",
    "        sent_obj.update({f\"Watson {k}\" : v for k, v in emotion.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Microsoft Azure API Results\n",
    "\n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/text-analytics/quickstarts/client-libraries-rest-api?tabs=version-3-1&pivots=programming-language-python#sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "George Bush: 100%|██████████| 1594/1594 [03:33<00:00,  7.45it/s]\n",
      "Osama bin Laden: 100%|██████████| 716/716 [01:38<00:00,  7.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "filename = \"C:\\\\Users\\\\spa1e17\\\\OneDrive - University of Southampton\\\\CNDWip\\\\APIKeys\\\\AzureKeys.json\"\n",
    "\n",
    "with open(filename, 'r') as fp:\n",
    "    keys = json.load(fp)\n",
    "    apikey = keys['KEY 1']\n",
    "    endpoint = keys['Endpoint']\n",
    "\n",
    "credential = AzureKeyCredential(apikey)\n",
    "endpoint=endpoint\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint, credential)\n",
    "\n",
    "for orator in docs.values():\n",
    "    \n",
    "    for sent_obj in tqdm(orator['sentences'], total = len(orator['sentences']), desc = orator['name']):\n",
    "  \n",
    "        text = [sent_obj['text']]\n",
    "        \n",
    "        response = text_analytics_client.analyze_sentiment(text, language=\"en\")\n",
    "        label = response[0].sentiment\n",
    "        score = response[0].confidence_scores[label]\n",
    "\n",
    "        if label == \"negative\":\n",
    "            score = score*-1\n",
    "        \n",
    "        sent_obj['azure sentiment'] = score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get TextBlob API Results\n",
    "\n",
    "https://textblob.readthedocs.io/en/dev/quickstart.html#sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "George Bush: 100%|██████████| 1594/1594 [00:01<00:00, 1493.64it/s]\n",
      "Osama bin Laden: 100%|██████████| 716/716 [00:00<00:00, 1383.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "for orator in docs.values():\n",
    "    \n",
    "    for sent_obj in tqdm(orator['sentences'], total = len(orator['sentences']), desc = orator['name']):\n",
    "  \n",
    "        text = sent_obj['text']\n",
    "        \n",
    "        sent_obj['textblob sentiment'] = TextBlob(text).sentiment[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Results to Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cndlib.cndutils import dump_jsonl\n",
    "import json\n",
    "print(type(docs))\n",
    "filename = os.path.join(os.getcwd(), \"gold_results.json\")\n",
    "with open(filename, 'w') as file:\n",
    "     file.write(json.dumps(docs))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(doc for doc in docs['laden']['sentences'])\n",
    "\n",
    "labels = ['text', 'function', 'hostile'] + [label for label in df.keys() if 'sentiment' in label and 'magnitute' not in label]\n",
    "display(df[labels][df.function.eq('elevation')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function(orator, entity):\n",
    "\n",
    "    \"\"\"\n",
    "    function to get the grouping of an entity from the orator's groupings\n",
    "    \"\"\"\n",
    "    if entity in docs[orator]['text']['groups']['ingroup']:\n",
    "        return \"ingroup\"\n",
    "    if entity in docs[orator]['text']['groups']['outgroup']:\n",
    "        return \"outgroup\"\n",
    "    return \"not found\"\n",
    "\n",
    "def assessment_test(col1, col2):\n",
    "\n",
    "    \"\"\"\n",
    "    function to test whether a sentiment scores matches ingroup/outgroup\n",
    "    \"\"\"\n",
    "\n",
    "    if col1 == \"positive\" or col1 == \"neutral\" and col2 == \"ingroup\":\n",
    "        return \"pass\"\n",
    "    if col1 == \"negative\" and col2 == \"ingroup\":\n",
    "        return \"fail\"\n",
    "    if col1 == \"negative\" and col2 == \"outgroup\":\n",
    "        return \"pass\"\n",
    "    if col1 == \"positive\" or col1 == \"neutral\" and col2 == \"outgroup\":\n",
    "        return \"fail\"\n",
    "    \n",
    "# create new dataframe based on filtered columns\n",
    "scores = lambda table, column, labels: table[table.column.isin(labels)], ignore_index = True)\n",
    "\n",
    "## iterate through the docs\n",
    "for orator in docs:\n",
    "    \n",
    "    # capture results\n",
    "    results = pd.DataFrame(docs[orator]['sentences'])\n",
    "    \n",
    "    ## create a dataframe for positive and negative results\n",
    "    dfs = dict()\n",
    "    dfs = {\"elevation\" : {\"result\" : None, \"df\" : scores(results, 'function', ['elevation'])}, \n",
    "           \"othering\" : {\"result\" : None, \"df\" : scores(results, 'function', ['othering'])}}\n",
    "\n",
    "    for obj in dfs.values():\n",
    "        \n",
    "        df = obj[\"df\"]\n",
    "            \n",
    "        # get the grouping for each entity\n",
    "        df[\"grouping\"] = df.apply(lambda x: get_group(orator, x[\"text\"]), axis = 1)\n",
    "        \n",
    "        # test whether sentiment score matches ingroup/outgroup        \n",
    "        df[\"test result\"] = df.apply(lambda x: assessment_test(x[\"label\"], x[\"grouping\"]), axis=1)\n",
    "        \n",
    "        # get the success scores for ingroup and outgroup\n",
    "        obj[\"result\"] = format(df[\"test result\"].value_counts(normalize = True)[\"pass\"], '.0%')\n",
    "        \n",
    "        # format dataframe\n",
    "        df.drop('mixed', axis = 1, inplace = True)\n",
    "        df['text'] = df['text'].str.title()\n",
    "        df.rename(columns = {\"score\" : \"sentiment score\", \"text\" : \"entity text\"}, inplace = True)\n",
    "        df.columns = df.columns.str.title()\n",
    "\n",
    "    docs[orator]['text']['analytics']['sentiment']['dfs'] = dfs\n",
    "    \n",
    "#     # display the outputs\n",
    "#     display_side_by_side([output[\"df\"] for output in dfs.values()],\n",
    "#                          [f\"{key.title()} scores for {docs[orator]['name']} has a True Positive Score of {obj['result']} from a total of {len(obj['df'])} Entities\"\n",
    "#                          for key, obj in dfs.items()])\n",
    "#     print()\n",
    "\n",
    "dfs = []\n",
    "captions = []\n",
    "for orator in docs.values():\n",
    "    for group, df in orator['text']['analytics']['sentiment']['dfs'].items():\n",
    "        dfs.append(df['df'])\n",
    "        captions.append(f\"{group.title()} scores for {orator['name']} has a Success of {df['result']} from a total of {len(df['df'])} Entities\")\n",
    "        \n",
    "display_side_by_side(dfs, captions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
